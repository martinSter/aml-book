[{"path":"index.html","id":"über-das-buch","chapter":"Über das Buch","heading":"Über das Buch","text":"Die Motivation für dieses Buch kam aus der Erkenntnis, dass viele kleine und mittelgrosse Unternehmen (KMU) der Schweiz zwar über grosse Datenmengen verfügen, aber nicht das nötige Knowhow haben, um die Daten zu analysieren und für die Optimierung von Entscheidungsprozessen zu nutzen. Mit diesem Buch möchte ich einen kleinen Beitrag leisten, den Knowhow Transfer von Fachhochschulen die Unternehmen zu katalysieren.Das Buch versucht, sowohl die klassischen Machine Learning Methoden als auch neueste Entwicklungen im Deep Learning mit einem Fokus auf die Anwendung zu vermitteln. Deep Learning kann als eine Teilmenge des Machine Learnings gesehen werden. Das heisst, jede Deep Learning Methode ist automatisch auch eine Machine Learning Methode. Machine Learning entält jedoch weitere Methoden, welche nicht dem Deep Learning zugeordnet werden können. Das Gebiet Machine Learning ist wiederum eine Teilmenge der Methoden der Künstlichen Intelligenz. Letztere enthält weitere Methoden, welche nicht dem Machine Learning zuzuordnen sind. Abbildung 0.1 versucht diesen Sachverhalt schematisch darzustellen.\nAbbildung 0.1: Unterscheidung zwischen KI, ML und DL.\nWir werden im ganzen Buch die folgenden (üblichen) Abkürzungen verwenden:Künstliche Intelligenz = KI (oft spricht man auch von AI, die Abkürzung für den englischen Begriff Artificial Intelligence ist).Machine Learning = MLDeep Learning = DLObwohl das Buch einen anwendungsorientierten Ansatz verfolgt, soll die mathematisch-statistische Intuition hinter den beschriebenen Modellen und Methoden nicht zu kurz kommen. Diese Intuition ist aus meiner Sicht zwingend, um beurteilen zu können, ob sich ein Modell überhaupt für ein gegebenes Problem eignet. Schluss geht es nämlich darum, dass wir mit dem Einsatz von Machine Learning einen Mehrwert für ein Unternehmen oder für die Gesellschaft schaffen können. Das erfordert, dass wir uns eingehend und kritisch mit den Modellen und deren Eignung für ein gegebenes Problem auseinander setzen.","code":""},{"path":"index.html","id":"zielgruppe","chapter":"Über das Buch","heading":"Zielgruppe","text":"Das Buch richtet sich insbesondere Fachhochschulstudierende der deutschsprachigen Schweiz mit einem intrinsischen Interesse quantitativen Methoden im Allgemeinen und Machine Learning im Besonderen. Vorausgesetzt werden Mathematikkenntnisse auf Stufe Mittelschule (Berufs- oder gymnasiale Matur), d.h. Sie sollten vertraut sein mit den Grundlagen bezüglich mathematischer Funktionen, der Integral- und Differentialrechnung sowie den wichtigsten Resultaten aus der Algebra. Ausserdem gehe ich davon aus, dass Sie bereits eine Einführung das Thema Statistik besucht haben und Konzepte aus der deskriptiven Statistik (Mittelwert, Median, Varianz, Quantile, etc.) sowie aus der Inferenzstatistik (Verteilungen, statistisches Testen, etc.) bekannt sind.Bevor Sie sich aber nun Sorgen machen: Kapitel 2 enthält eine Einführung die wichtigsten Mathematik- und Statistikgrundlagen, die nötig sind für das Verständnis von Machine Learning Modellen.Da ich mit diesem Buch einen anwendungsorientierten Ansatz verfolge, werden wir auch das Programmieren einsteigen. Dazu verwenden wir diesem Buch die Programmiersprache R. Es werden keine Vorkenntnisse vorausgesetzt. Kapitel 3 enthält eine kurze Einführung die Programmiersprache R und verweist Sie auf weiterführende Ressourcen zum Thema Programmieren. Jedes Modell, das wir uns anschauen werden, ist mit R-Code dokumentiert, dass Sie lernen, wie die Modelle der Praxis angewendet werden können.","code":""},{"path":"index.html","id":"aufbau-des-buchs","chapter":"Über das Buch","heading":"Aufbau des Buchs","text":"Das Buch enthält folgende Kapitel:Kapitel 1: Einführung das Thema Machine Learning mit Definitionen sowie Anwendungsbeispielen.Kapitel 2: Wichtigste Mathematik- und Statistikgrundlagen, die für das Verständnis der Modelle den späteren Kapitel elementar sind.Kapitel 3: Einführung das Programmieren mit R sowie Überblick über die wichtigsten R-Packages, die wir verwenden werden.Kapitel 4: Hier erlernen wir die Grundmodelle, um Regressionsprobleme zu lösen. Es sind lineare Modelle, bedeutet, dass die funktionale Form der Modelle linear von den Parametern des Modells abhängen. Grafisch bedeutet dies, dass ein solches Modell im einfachsten Fall durch eine Gerade beschrieben werden kann.Kapitel 5: diesem Kapitel lernen wir die Grundmodelle für das Klassifikationsproblem kennen. Diese Modelle führen typischerweise zu einer linearen Entscheidungsgrenze (engl. Decision Boundary) zwischen den verschiedenen Klassen, die wir unterscheiden oder klassifizieren wollen.Kapitel 6: Damit wir ML der Praxis anwenden können, lernen wir hier die typische ML-Pipeline kennen. Sie werden die Techniken und Methoden kennen lernen, die es braucht, um überhaupt erst den Punkt zu kommen, um ein ML-Modell rechnen zu können. Oft werden diese Techniken und Methoden unter dem Begriff Preprocessing der Daten zusammengefasst. Doch die Pipeline endet nicht mit dem Rechnen eines ML-Modells. Danach muss ein Modell evaluiert werden und wenn Sie als Analyst*zufrieden sind, müssen Sie sich Gedanken machen, wie das Deployment des Modells aussehen soll. Das heisst, wie kann Ihr Modell Dritten zur Verfügung gestellt werden? Wir werden uns hier auch kurz mit den wichtigsten Techniken aus dem Unsupervised Learning befassen.Kapitel 7: Nach den ersten linearen Modellen für das Regressions- und Klassifikationsproblem lernen wir hier ein flexibleres Modell kennen, nämlich den Entscheidungsbaum (engl. Decision Tree). Entscheidungsbäume eignen sich sowohl für das Regressions- als auch für das Klassifikationsproblem. Obwohl sie realen Projekten typischerweise anderen Modellen unterlegen sind, wenn es um die Vorhersagequalität geht, sind sie trotzdem attraktive Modelle, da sie gut visualisierbar sind.Kapitel 8: Aufbauend auf den Entscheidungsbäumen aus dem vorherigen Kapitel können sehr mächtige Modelle erstellt werden, die der Praxis oft die besten Vorhersagen liefern. Weil es sich dabei üblicherweise um eine clevere Aggregierung der Resultate einer grossen Anzahl individueller Entscheidungsbäume handelt, werden diese Modelle Ensembles genannt. Wie die individuellen Entscheidungsbäume eignen sich Ensembles sowohl für das Regressions- als auch für das Klassifikationsproblem.Kapitel 9: Ein weiteres mächtiges Modell, das sich sowohl für das Regressions- als auch für das Klassifikationsproblem eignet, sind die Support Vector Machines. Ihre Popularität ist mit dem Aufstieg von Deep Learning etwas verblasst. Es lohnt sich aber immer noch allemal, diese Familie von Modellen kennen zu lernen, insbesondere auch weil sie nicht als Blackbox-Modelle gelten und theoretisch gut fundiert sind.Kapitel 10: Ab diesem Kapitel steigen wir das Thema Deep Learning ein. Sie werden die Architektur von einfachen Articial Neural Networks (ANNs) kennen lernen. Ausserdem schauen wir uns diesem Kapitel den genialen Backpropagation Algorithmus anhand eines einfachen linearen Regressionsproblems . Dieser Algorithmus ist der Schlüssel für die viel diskutierten Fortschritte im Bereich der künstlichen Intelligenz, weil er das Trainieren von riesigen Modellen überhaupt erst möglich macht.Kapitel 11: Hier lernen wir sogenannte Convolutional Neural Networks (CNNs) kennen. Sie sind die Basis für die Fortschritte auf dem Gebiet Computer Vision und erlauben beispielsweise Anwendungen im Bereich automatische Gesichtserkennung Bildern oder Videos.Kapitel 12: Nach ANNs und CNNs lernen wir hier Recurrent Neural Networks (RNNs) kennen. Diese Modelle bilden die Basis für Probleme, denen die Daten als Sequenzen vorliegen. Das können einache Zeitreihen (z.B. Börsenkurse) sein, aber auch komplexere Sequenzdaten wie beispielsweise geschriebene oder gesprochene Sprache oder Tonaufnahmen.Kapitel 13: diesem letzten Kapitel geht es schliesslich um Generative KI. Wir beschäftigen uns hier also mit Modellen, die nicht nur einfach ein Vorhersageprobleme lösen können, sondern auch neue Inhalte (z.B. Texte, Musik, Bilder) generieren können. Abbildung 0.2 enthält als Beispiel den Output einer generativen Software, die basierend auf einem Prompt ein Bild erstellt. Nach dem Lesen dieses Kapitels sollten Sie ein grundlegendes Verständnis für die Funktionsweise von Modellen wie Chat-GPT haben.\nAbbildung 0.2: Beispielsoutput einer generativen Bildgenerierungssoftware (https://stablediffusionweb.com/) basierend auf dem Prompt “title image textbook Machine Learning targeting small medium companies.”\n","code":""},{"path":"index.html","id":"weiterführende-literatur","chapter":"Über das Buch","heading":"Weiterführende Literatur","text":"Ein grosser Teil des vorliegenden Buchs baut auf bestehenden Büchern zum Thema Machine Learning auf. Ich werde im Buch immer wieder auf die Quellen verweisen. Die wichtigsten Referenzen für dieses Buch sind folgende:Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani. (2021). Introduction Statistical Learning: Applications R. New York: Springer. 2nd Edition.Aurélien Géron. (2019). Hands-Machine Learning Scikit-Learn, Keras, TensorFlow: Concepts, Tools, Techniques Build Intelligent Systems. Sebastopol: O’Reilly Media Inc. 3rd Edition.Christopher M. Bishop. (2006). Pattern Recognition Machine Learning. Berlin, Heidelberg: Springer.Kevin P. Murphy. (2012). Machine Learning Probabilistic Perspective. MIT Press.Die ersten beiden Referenzen sind einführende Texte und können parallel zum vorliegenden Buch gelesen werden. Die letzten zwei Referenzen sind fortgeschrittene Texte und ich empfehle, sie erst nach dem vollständigen Verständnis des vorliegenden Buchs oder der ersten beiden Referenzen zu lesen.","code":""},{"path":"index.html","id":"lizenz","chapter":"Über das Buch","heading":"Lizenz","text":"Das vorliegende Buch ist unter Lizenz CC -NC-SA 4.0 DEED (Namensnennung, nicht-kommerziell, Weitergabe unter gleichen Bedingungen 4.0 International) lizenziert. Bitte halten Sie sich die Lizenzbedingungen.","code":""},{"path":"index.html","id":"kontakt","chapter":"Über das Buch","heading":"Kontakt","text":"Für Fragen und Anregungen zum Buch stehe ich gerne zur Verfügung:Martin Sterchi\nRiggenbachstrasse 16\n4600 Oltenmartin.sterchi@fhnw.ch","code":""},{"path":"intro.html","id":"intro","chapter":"1 Einführung","heading":"1 Einführung","text":"diesem Kapitel geht es darum zu verstehen, ML überhaupt ist, warum es nützlich sein kann und typische Anwendungsfälle von ML sind. Wir werden ausserdem verschiedene Unterkategorien von ML kennen lernen.","code":""},{"path":"intro.html","id":"was-ist-machine-learning","chapter":"1 Einführung","heading":"1.1 Was ist Machine Learning?","text":"Im Prinzip geht die Geschichte des MLs weit zurück, nämlich zu den Anfängen der Statistik. Viele Modelle, die heutzutage im ML angewendet werden sind nämlich eigentlich von Statistiker*innen erfundene Modelle. Die Geschichte des MLs und der Statistik sind darum eng verknüpft. Einen eigentlichen Startpunkt des MLs könnte man vielleicht den 1960er Jahren ausmachen, mit den Arbeiten von Frank Rosenblatt1, welcher das sogenannte Perceptron und einen dazugehörigen Lernalgorithmus prägte (dazu später mehr). Danach blieb es aber rund 20 Jahre relativ ruhig bis die Forschung im Bereich Machine Learning richtig Fahrt aufnahm. Ein grosser Schub für die Entwicklung von ML ging vom Aufkommen von extrem grossen Datenmengen (Big Data) und dem Internet aus. Das führte nämlich dazu, dass sich immer mehr Leute aus den Fachbereichen Informatik und Computer Science mit dem Thema ML befassten und effiziente Hard- und Software sowie algorithmische Kniffs und Tricks beisteuerten. Ausserdem ermöglichte das Internet den Zugang zu gewaltigen Datenmengen Bildern, Videos, Klicks, etc. - denken Sie beispielsweise nur schon die Informationen, die jede*r von uns tagtäglich im Internet hinterlässt. Ein weiterer Schub für das Machine Learning war (und ist) zudem die immer besser werdende Rechenleistung von Computern. Diese Entwicklungen haben sich im November 2022 kulminiert der erstmaligen breiten öffentlichen Wahrnehmung von sogenannten Large Language Models wie ChatGPT.Wie der Name sagt, geht es im ML darum, dass eine Maschine (oder präziser, ein Computer) aus einem gegebenen Datensatz automatisch Muster lernt, ohne dass ein Mensch dem Computer (explizit) sagen muss, er lernen soll. Der Mensch gibt jedoch dem Computer die Rahmenbedingungen für das selbständige Lernen vor. Die erlernten Muster sind selbstverständlich nur nützlich, wenn sie genereller Natur sind und auch für neue bzw. zukünftige Beobachtungen gelten. Beispiel: ein Spital hat während der Corona Pandemie ein Modell trainiert, um den täglichen Pflegebedarf je nach Wochentag, Saison, und weiteren Indikatoren vorherzusagen. Das Modell funktioniert nun nach der Pandemie aber nicht wunschgemäss und prognostiziert der Tendenz einen zu hohen Pflegebedarf. Das Problem ist, dass die erlernten Muster nicht gut auf eine Zeit nach der Pandemie generalisierbar sind. Mit anderen Worten: die Trainingsdaten waren nicht repräsentativ genug.Bevor wir etwas konkreter anschauen, wie genau ein Computer selbständig aus Daten lernen kann, schauen wir uns die Definitionen von zwei Experten im Gebiet ML :“[Machine Learning ] field study gives computers ability learn without explicitly programmed.” Arthur Samuel, 1959“Machine Learning science (art) programming computers can learn data.” Aurélien Géron2Zusammenfassend lässt sich sagen, dass wir mit ML dem Computer die Möglichkeit geben, automatisch und selbständig aus Daten zu lernen. Nichtsdestotrotz braucht es Sie als ML-Expert*, und zwar wie folgt:Sie entscheiden sich für ein spezifisches ML Modell. Typischerweise kann ein ML Modell durch eine mathematische Funktion (siehe Kapitel 2) charakterisiert werden. ML Modelle können unterschiedlich flexibel sein und es liegt im Ermessen von Ihnen, wie flexibel das Modell sein soll. Sie müssen bei der Wahl des Modells die Komplexität des Problems berücksichtigen. Grundsätzliche gilt bei der Wahl des Modells, dass flexiblere Modelle komplexere Sachverhalte abbilden können. Ein zu flexibles Modell kann aber zu Overfitting führen, aber dazu später mehr. Dieser Schritt wird im Fachjargon typischerweise Model Selection (Modelauswahl) genannt.Sobald Sie das Modell ausgewählt haben, übergeben Sie dem Computer (etwas vereinfacht gesagt) das Modell, einen Datensatz sowie einen Lernalgorithmus. Nun hat der Computer alle Zutaten, um automatisch zu lernen. Doch lernt er eigentlich? Der Computer lernt die Parameter Ihres gewählten Modells, dass das Modell sich optimal die Daten anpasst. Dieser Schritt wird im Fachjargon Model Training (Trainieren des Modells) genannt.Falls Sie mit dem erlernten Modell zufrieden sind, können Sie es nun entweder dazu verwenden Vorhersagen zu machen oder um Zusammenhänge den Daten zu interpretieren und daraus wertvolle Einsichten gewinnen. Dieser Schritt wird im Fachjargon als Model Inference (Modellinferenz) zusammengefasst. Typischerweise sind Sie der Realität mit dem ersten erlernten Modell allerdings noch nicht zufrieden und gehen zurück zu Schritt 1 und wählen ein anderes Modell.Es handelt sich bei dieser Vorgehensweise um eine sehr allgemeine Beschreibung des Machine Learning Prozesses. Wie diese drei Schritte konkret funktionieren, werden Sie den nachfolgenden Kapiteln dieses Buchs erfahren.","code":""},{"path":"intro.html","id":"wann-macht-es-sinn-ml-einzusetzen","chapter":"1 Einführung","heading":"1.2 Wann macht es Sinn ML einzusetzen?","text":"Ein ML Modell zu trainieren kann viel Zeit und Geld kosten. Zum Beispiel müssen Sie unter Umständen überhaupt erst die Daten sammeln (oder von einem Datendienstleister kaufen), um ein Modell zu trainieren. Oder das Projekt ist komplex, dass Sie als Analyst*unzählige Stunden benötigen, um die Daten überhaupt erst eine Form zu bringen, die es erlaubt ein Modell zu trainieren. Für neuartige DL Modelle oder Generative KI kann das Trainieren bzw. Lernen eines Modells durch den reinen Stromverbrauch bzw. die vom Cloud-Betreiber Rechnung gestellten Kosten hoch sein, dass sich Ihr ursprüngliches Vorhaben nicht mehr lohnt. Es ist also ungemein wichtig, dass Sie sich vor Projektbeginn gut überlegen, ob ML für Ihr vorliegendes Problem überhaupt Sinn macht und einen Mehrwert generieren kann.Folgende Daumenregeln3 können Ihnen dabei helfen, zu entscheiden, ob ML für Ihr Projekt Sinn macht:Ihr Problem entspricht einem Standard ML-Problem, das bereits mehrfach gelöst wurde und für das es sogenannte “--shelf” Lösungen gibt. Beispiel: Sie wollen das Sentiment (positive vs. negative Grundhaltung) von Social Media Posts über Ihr Unternehmen automatisch klassifizieren. Dazu gibt es viele vortrainierte Modelle, die teilweise gratis verwendet werden können.Der manuelle Arbeitsaufwand ist sehr gross, wenn das Problem durch Menschen gelöst werden soll. Das Problem ist aber ansonsten klar strukturiert und benötigt keinen grossen kognitiven Einsatz eines Menschen. Beispiel: den Post-Verteilzentren werden die von Hand geschriebenen Postleitzahlen (PLZ) problemlos mittels Computer bzw. ML Modellen erkannt und “gelesen” und die Briefe und Pakete entsprechend sortiert.Komplexe Probleme, denen ein Mensch keinen Überblick hat, weil grosse und komplexe Datenmengen vorhanden sind. Wir Menschen haben grosse Mühe damit, Rohdaten (reinen Datentabellen) irgendwelche Muster zu erkennen. diesem Fall können wir entweder versuchen, die Daten zu visualisieren oder mithilfe von ML Zusammenhänge zu lernen, die wir sonst nicht erkennen könnten. Ein illustratives Beispiel ist das Anscombe Quartett4, das vier kleine Stichproben mit jeweils elf Datenpunkten enthält. Jeder Datenpunkt wird durch eine \\(x\\) und eine \\(y\\) Variable beschrieben. Die vier \\(x\\)- sowie die vier \\(y\\)-Variablen haben identische Mittelwerte. Erst eine einfache Visualisierung der vier Stichproben mithilfe eines Streudiagramms zeigt die Muster sowie die Unterschiede zwischen den vier Stichproben deutlich auf.","code":"#>    x1 x2 x3 x4    y1   y2    y3    y4\n#> 1  10 10 10  8  8.04 9.14  7.46  6.58\n#> 2   8  8  8  8  6.95 8.14  6.77  5.76\n#> 3  13 13 13  8  7.58 8.74 12.74  7.71\n#> 4   9  9  9  8  8.81 8.77  7.11  8.84\n#> 5  11 11 11  8  8.33 9.26  7.81  8.47\n#> 6  14 14 14  8  9.96 8.10  8.84  7.04\n#> 7   6  6  6  8  7.24 6.13  6.08  5.25\n#> 8   4  4  4 19  4.26 3.10  5.39 12.50\n#> 9  12 12 12  8 10.84 9.13  8.15  5.56\n#> 10  7  7  7  8  4.82 7.26  6.42  7.91\n#> 11  5  5  5  8  5.68 4.74  5.73  6.89"},{"path":"intro.html","id":"anwendungsfälle-von-ml","chapter":"1 Einführung","heading":"1.3 Anwendungsfälle von ML","text":"diesem Abschnitt stelle ich erfolgreiche Anwendungsfälle von ML vor. Einige davon treffen Sie womöglich tagtäglich Ihrem Alltag :Spam Filter sind ein frühes Beispiel einer erfolgreichen Anwendung von ML. Ein Klassifikationsmodell entscheidet dabei automatisch aufgrund der Inhalte einer Email, des Betreffs sowie des Absenders, ob es sich um eine Spam oder eine sogenannte Ham Email (unproblematische Email) handelt. Falls Sie gängige Email Software verwenden, dann arbeitet im Hintergrund ein Spam Filter daran, Sie vor lästigen Emails zu schützen.Ein grosser Teil des wirtschaftlichen Erfolgs von Google basiert auf der Idee, dass aufgrund der Suchhistorie hervorgesagt werden kann, welche Nutzerin oder welcher Nutzer mit welcher Wahrscheinlichkeit eine bestimmte Werbung anklickt. Dies erlaubt Google für jede Nutzer*die Werbung mit den höchsten “Erfolgschancen” zu schalten. Da jeder Klick Einnahmen generiert, ist es für das Geschäftsmodell von Google entscheidend, dass möglichst viele Klicks stattfinden.Ein grosser Bereich des MLs und speziell des DLs befasst sich mit Computer Vision. Dabei geht es darum, das Hauptmotiv von Bildern zu klassifizieren (z.B. Zeigt ein Bild ein Tier oder einen Menschen?), Objekte Bildern zu entdecken (z.B. Enthält das Bild eine Person?) und das entdeckte Objekt dann auch zu klassifizieren (z.B. Handelt es sich bei der Person um XY?). Als konkreteres Beispiel können Sie sich einen Industriebetrieb vorstellen, welcher ein Computer Vision Modell einsetzen möchte, um den Abnützungsgrad der von ihnen produzierten Werkzeuge automatisch zu erkennen und den Kundinnen und Kunden den optimalen Ersatzzeitpunkt für das Werkzeug vorhersagen zu können.Ähnlich wie im vorherigen Beispiel gibt es bereits viele Anwendungen im öffentlichen Verkehr, denen es um Predictive Maintenance geht. Z.B. kann der optimale Wartungszeitpunkt für eine Weiche oder einen Gleisabschnitt aufgrund einer Vielzahl Indikatoren und Messungen vorhergesagt werden.Ein grosses Einsatzgebiet für ML ergibt sich im Finanzsektor durch das automatische Erkennen von potentiell betrügerischen Transaktionen. Falls Sie auch schon mal eine Kreditkartentransaktion direkt Telefon einer Kundenberaterin oder einem Kundenberater bestätigen mussten, dann ist es wahrscheinlich, dass Ihre Transaktion von einem ML System zur manuellen Überprüfung geflaggt wurde. diesem Zusammenhang spricht man manchmal auch vom Erkennen von Anomalien (engl. Anomaly Detection).Sogenannte Recommender Systems sind insbesondere Online Verkaufspunkten von grossem Nutzen. Betreiben Sie beispielsweise einen grossen Onlinehandel, dann wollen Sie Ihren Kundinnen und Kunden Produkte zum Kauf vorschlagen. Dazu verwenden Sie ein Modell, das basierend auf der Ähnlichkeit zwischen Kundinnen und Kunden potentiell interessante Produkte vorschlägt.Die rasanten Entwicklungen im Bereich Natural Language Processing (NLP) den letzten 10 Jahren haben viele neue und interessante Anwendungsgebiete zutage gefördert. Zum Beispiel eignen sich Large Language Models (LLMs) als erste Anlaufstelle für Kundinnen und Kunden (automatisierter Kundenservice). LLMs werden vermutlich aber auch immer mehr internen Prozessen Unternehmen eingesetzt, z.B. um komplexe Dokumente zusammenzufassen oder Sitzungsprotokolle zu erstellen.Die obige Liste ist bei weitem nicht komplett und die Entwicklungen im Bereich ML sind aktuell rasant, dass jeden Tag eine grosse Zahl von neuen ML-basierten Produkten und Dienstleistungen auf den Markt kommen.","code":""},{"path":"intro.html","id":"supervised-vs.-unsupervised-learning","chapter":"1 Einführung","heading":"1.4 Supervised vs. Unsupervised Learning","text":"Den Unterschied zwischen dem Supervised Learning und dem Unsupervised Learning können wir besten erklären, indem wir uns mit ein paar mathematischen Grundlagen des Machine Learnings befassen. Keine Sorge, diese Grundlagen sind sehr einfach, aber versuchen Sie, diese bereits gut zu verstehen, denn wir bauen später darauf auf.Im Supervised Learning haben wir einerseits sogenannte Input-Daten und andererseits einen Output, den wir vorhersagen wollen. Für die Input-Daten gibt es ganz viele verschiedene Begriffe, die synonym verwendet werden: z.B. Features, unabhängige Variablen, Attribute, Prädiktoren. Dasselbe gilt für den Output, hier gibt es folgende Synonyme: Zielvariable, abhängige Variable, Label, oder auch einfach \\(y\\). Unsere Konvention hier ist aber folgende: es gibt Input-Daten (oder Input-Variablen) und einen Output (oder Output-Variable).Die Input-Daten für eine Beobachtung \\(\\) schreiben wir mathematisch wie folgt:\\[\n\\mathbf{x}_i=\\begin{pmatrix} x_{i1} \\\\ x_{i2} \\\\ \\vdots \\\\ x_{ip} \\end{pmatrix},\n\\]\nDiese Notation bedarf ein paar Erklärungen:Den Index \\(\\) brauchen wir, um die verschiedenen Beobachtungen zu kennzeichnen. \\(\\) kann eine Ganzzahl zwischen \\(1\\) und \\(n\\) annehmen, wobei \\(n\\) die Anzahl Beobachtungen im Datensatz bezeichnet. Wenn wir zum Beispiel etwas über die Input-Daten der dritten Beobachtung sagen wollen, dann können wir die Notation \\(\\mathbf{x}_3\\) verwenden.Für jede Beobachtung \\(\\) haben wir insgesamt \\(p\\) Variablen, welche die verschiedenen Attribute einer Beobachtung enthalten. \\(x_{i1}\\) bezeichnet also die erste Variable der -ten Beobachtung, \\(x_{i2}\\) die zweite Variable der -ten Beobachtung und \\(x_{ip}\\) die p-te (letzte) Variable der -ten Beobachtung.Sie oben sehen, ist aus mathematischer Sicht ein Spaltenvektor. Im Moment reicht es, wenn Sie wissen, dass wir mit diesem Spaltenvektor die Input-Daten einer Beobachtung kompakt darstellen können.Neben den Input-Daten haben wir im Supervised Learning aber wie erwähnt auch einen Output und den bezeichnen wir üblicherweise mit \\(y_i\\). Auch hier hilft uns der Index \\(\\) dabei, die Beobachtungen eindeutig zu kennzeichnen. Schauen wir uns besten kurz ein konkretes Beispiel :AufgabeStellen Sie sich vor, wir versuchen mithilfe eines Datensatzes von 5000 getätigten Kreditkartentransaktionen ein Modell zu trainieren, das vorhersagen kann, ob es sich bei einer gegebenen Transaktion um eine betrügerische Transaktion handelt oder nicht. Jede Transaktion Ihrem Datensatz entspricht einer Beobachtung \\(\\). Der Output \\(y_i\\) diesem Beispiel ist eine kategorische Variable, die wir als \\(y_i \\\\{\\text{Betrug},\\;\\text{kein Betrug}\\}\\) darstellen können. Ausserdem haben Sie folgende Input-Daten:\\[\n\\mathbf{x}_i=\\begin{pmatrix} \\text{Transaktionsbetrag} \\\\ \\text{Land des Zahlungsempfaengers} \\\\ \\text{Zeitstempel der Transaktion} \\end{pmatrix}\n\\]Welche Werte nehmen diesem Beispiel \\(n\\) und \\(p\\) ?\n\\(n=100\\) und \\(p=3\\)\n\n\\(n=5000\\) und \\(p=3\\)\n\n\\(n=3\\) und \\(p=5000\\)\n\n\\(n=100\\) und \\(p=4\\)\nWir haben 5000 Beobachungen, darum gilt \\(n=5000\\). Ausserdem haben wir 3 Variablen (Attribute), darum gilt \\(p=3\\).\nFalsch\n\nRichtig\n\nFalsch\n\nFalsch\nWichtig: Beim Supervised Learning geht es um ML Probleme, denen sowohl Input-Daten als auch ein Output vorhanden ist. Ziel beim Supervised Learning ist es, ein Modell zu trainieren, das basierend auf den Input-Daten möglichst gute Vorhersagen für den Output macht. Es geht also hier um Vorhersageprobleme. einem gewissen Sinn ist der Output die überwachend Instanz (engl. Supervisor), welche den Lernprozess des Modells kontrolliert.Im Gegensatz zum Supervised Learning haben wir im Unsupervised Learning nur Input-Daten und keinen Output. Im Unsupervised Learning geht es darum, aus den Input-Daten interessante Muster zu lernen, welche für bessere unternehmerische Entscheidungen verwendet werden können. Ein einfaches Beispiel ist das Clustering von Kundinnen und Kunden eines Unternehmens ähnliche Kundengruppen, dass die verschiedenen Kundengruppen gezielter mit Marketingaktionen angesprochen werden können. Techniken, um komplexe Datensätze zu visualisieren, werden typischerweise auch zum Unsupervised Learning gezählt.Neben dem Supervised und dem Unsupervised Learning gibt es noch eine dritte Kategorie von Machine Learning, nämlich das Reinforcement Learning (RL). Dieser Kategorie gehören Modelle , die (virtuelle) Agenten trainieren, dass sie langfristig möglichst optimal handeln. Das bekannteste Beispiel aus dem RL ist Googles AlphaGo Agent, welcher den menschlichen Go Weltmeister im Jahr 2017 schlug.5. Reinforcement Learning ist aber auch eine wichtige Komponente der Optimierung von grossen Sprachmodellen wie ChatGPT. einer ersten Fassung dieses Buchs werden wir uns nicht (oder nur Rande) mit RL befassen.Die Unterscheidung zwischen den drei Arten von Machine Learning ist im oberen Teil der Abbildung 1.1 visualisiert:\nAbbildung 1.1: Die verschiedenen Kategorien des Machine Learnings und deren Hierarchie.\n","code":""},{"path":"intro.html","id":"regression-vs.-klassifikation","chapter":"1 Einführung","heading":"1.5 Regression vs. Klassifikation","text":"der Kategorie des Supervised Learnings unterscheiden wir weiter zwischen Regressions- und Klassifikationsproblemen (siehe auch Abbildung 1.1).Im Regressionsproblem ist der Output eine stetige Variable (Intervall- oder Verhältnisskalierung), d.h. die Variable enthält reelle (numerische) Werte. Mathematisch schreibt man dies als \\(y_i \\\\mathbb{R}\\), wobei \\(\\mathbb{R}\\) die Menge der reellen Zahlen beschreibt.Im Klassifikationsproblem ist der Output bzw. die Zielvariable eine kategorische Variable (Nominal- oder Ordinalskalierung). Mathematisch schreibt man dies als \\(y_i \\\\{1, \\dots, C\\}\\), wobei \\(C\\) die Anzahl Kategorien beschreibt. Wenn wir nur \\(C=2\\) Kategorien haben wie im Beispiel oben mit \\(y_i \\\\{\\text{Betrug}, \\text{kein Betrug}\\}\\) sprechen wir von einem binären Klassifikationsproblem. Falls \\(C>2\\) sprechen wir vom mehrklassigen (engl. multiclass) Klassifikationsproblem.AufgabeWelche der folgenden Probleme sind Regressionsprobleme?\nVorhersage des Lohns der Leiter*eines Unternehmens basierend auf Profit, Marktkapitalisation, Anzahl Mitarbeitender, sowie Sektor, dem das Unternehmen tätig ist.\n\nBasierend auf der aktuellen Marktlage und weiteren wirtschaftlichen Aspekten wollen Sie den morgigen Preis einer bestimmten Aktie vorhersagen\n\nVorhersage ob eine Person, welche ein bestimmtes Youtube Video schauen , volljährig ist oder nicht.\n\nEine Bank möchte mithilfe von historischen Daten vorhersagen, ob ein bestimmter Kunde zahlungsunfähig wird oder nicht.\n\nEin Detailhandelsunternehmen möchte vorhersagen, ob eine Kundin ein Produkt aus der Kategorie , B, C, oder kein Produkt kauft.\n\nVorhersage von Hauspreisen basierend auf Attributen wie der Grösse, Anzahl Zimmer, Seeblick (ja/nein), Steuerlast, etc.\n\nEin Unternehmen lanciert ein neues Produkt und schätzt anhand von Konkurrenzprodukten, ob das eigene Produkt ein Erfolg wird oder nicht.\n\nRichtig\n\nRichtig\n\nFalsch\n\nFalsch\n\nFalsch\n\nRichtig\n\nFalsch\n","code":""},{"path":"intro.html","id":"parametrische-vs.-nicht-parametrische-modelle","chapter":"1 Einführung","heading":"1.6 Parametrische vs. nicht-parametrische Modelle","text":"Ein ML Modell gehört entweder der Familie parametrischer Modelle oder der Familie nicht-parametrischer Modelle . Dabei spielt es keine Rolle, ob wir mit dem Modell ein Regressions- oder ein Klassifikationsproblem lösen wollen.Womöglich sind Sie Ihrer Ausbildung bereits parametrischen Modellen begegnet, denn das einfache lineare Regressionsmodell ist ein typisches Beispiel für ein parametrisches ML Modell. Das Modell ist vollkommen charakterisiert durch die beiden lernbaren (optimierbaren) Parameter \\(w_0\\) und \\(w_1\\)6 und kann wie folgt (mathematisch) aufgeschrieben werden:\\[\n\\hat{y_i} = f(x_i)=w_0 + w_1 \\cdot x_i\n\\]\nWenn Ihnen der obige Ausdruck noch fremd vorkommt, dann ist das nicht schlimm. Wir werden im Kapitel 4 ausführlich auf lineare Regressionsmodelle eingehen. Im Moment müssen Sie nur wissen, dass ein parametrisches Modell wie oben mit einer mathematischen Funktion beschrieben werden kann und dass diese Funktion durch lernbare Parameter (hier \\(w_0\\) und \\(w_1\\)) charakterisiert wird.Nicht-parametrische Modelle wiederum sind Modelle, welche nicht (oder zumindest nicht explizit) durch Parameter charakterisiert sind. besten schauen wir uns gleich ein einfaches nicht-parametrisches Modell , nämlich das K-Nearest-Neighbors (KNN) Modell. Stellen Sie sich vor, Sie haben einen Datensatz mit 55 Produkten aus Ihrem Sortiment. Sie haben jedes dieser 55 Produkte auf Instagram und auf Tiktok durch Influencer*innen bewerben lassen. Für jedes der 55 Produkte hatten Sie ein Werbebudget für Instagram (\\(x_{i1}\\)) und ein Werbebudget für Tiktok (\\(x_{i2}\\)). Ende des Geschäftsjahrs haben Sie für jedes der 55 Produkte bestimmt, ob die Absatzziele erreicht wurden oder nicht (Output \\(y_i\\)). Die erfolgreichen Produkte (= Absatzziel erreicht) sind untenstehender App als blaue Punkte eingezeichnet. Die roten Dreiecke repräsentieren die nicht-erfolgreichen Produkte. Sie sehen, dass erfolgreiche Produkte tendenziell höhere Instagram und Tiktok Werbebudgets aufwiesen als nicht-erfolgreiche Produkte. Sie möchten nun ein Modell schätzen, dass die Produkte automatisch klassifizieren kann. Dazu verwenden Sie das KNN Modell, das die \\(K\\) nächsten Nachbarn unter den 55 gegebenen Produkten sucht und dann die häufigste Beobachtung unter den \\(K\\) nächsten Nachbarn vorhersagt. anderen Worten: wir suchen die \\(K\\) ähnlichsten Beobachtungen und nutzen diese, um eine Vorhersage zu machen.Selbstverständlich spielt der konkrete Wert von \\(K\\) hier eine grosse Rolle - sollen wir nur \\(K=1\\) Nachbarn berücksichtigen? Oder \\(K=10\\) Nachbarn? Die erste Abbildung der App zeigt nicht nur die 55 Datenpunkte, sondern auch die Entscheidungsgrenze (schwarz). Untersuchen Sie kurz, wie sich diese Entscheidungsgrenze verändert, wenn Sie \\(K\\) erhöhen oder reduzieren.Ausserdem können Sie der ersten Abbildung auch den schwarzen Punkt mit der Maus setzen, wodurch Ihnen die \\(K\\) nächsten Punkte des schwarzen Punkts angezeigt werden.Die zweite Abbildung zeigt die Entscheidungsregionen mit unterschiedlicher Intensität je nachdem wie sicher sich das Modell ist. einer Region, der alle \\(K\\) Nachbarn nicht-erfolgreiche Produkte sind, sind wir uns eher sicher bezüglich der Vorhersage als einer Region, der die Anteile zwischen erfolgreichen und nicht-erfolgreichen Produkten ausgeglichen sind.Um die \\(K\\) nächsten Nachbarn zu finden, müssen wir die Distanzen zwischen Punkten rechnen können. Dazu verwenden wir die Euklidische Distanz, welche wir Kapitel 2 kennen lernen werden.Das KNN Modell ist ein sehr einfaches ML Modell, welches der Praxis allerdings nicht allzu häufig angewendet wird. Warum nicht? Weil es sogenannten Fluch der Dimensionalität (engl. Curse Dimensionality) leidet. Doch bedeutet das? Je mehr Input-Variablen wir haben, desto weiter entfernt sind Datenpunkte voneinander (das ist etwas, das man sich nur schwer vorstellen kann, aber Sie können es mir für den Moment einfach mal glauben). Das KNN beruht auf der Grundidee, dass wir \\(K\\) nahe, ähnliche Beobachtungen für die Vorhersage verwenden. Wenn diese \\(K\\) nahen Beobachtungen im hochdimensionalen Raum (= viele Input-Variablen) nicht mehr nahe sind, dann funktioniert auch das Modell nicht mehr gut.Aufgaben1. Stellen Sie sich vor, Sie haben folgendes Klassifikationsproblem, das Sie mit KNN lösen wollen. Welche Kategorie prognostiziert ein KNN Modell für den Punkt \\(x\\) der unten stehenden Abbildung?\nBlauer Kreis.\n\nBeide Klassen sind gleich wahrscheinlich.\n\nRotes Kreuz.\n\nFalsch\n\nFalsch\n\nRichtig\n2. ist der Wert für \\(K\\) für das KNN Modell der oben stehenden Abbildung?\n5\n\n2\n\n3\n\n10\n\nRichtig\n\nFalsch\n\nFalsch\n\nFalsch\n3. Stellen Sie sich vor, Sie haben folgendes Regressionsproblem, das Sie mit KNN lösen wollen. ist die Vorhersage für den Punkt \\(x\\) für das KNN-Regressionsmodell der unten stehenden Abbildung?\n4\n\n20\n\n5\n\nRichtig\n\nFalsch\n\nFalsch\n","code":""},{"path":"intro.html","id":"machine-learning-pipeline","chapter":"1 Einführung","heading":"1.7 Machine Learning Pipeline","text":"Abbildung 1.2 zeigt, wie eine typische ML-Pipeline aussieht.7\nAbbildung 1.2: Eine typische ML-Pipeline.\nSie starten typischerweise mit einem Problem oder einer Herausforderung. Ihr ganzes Projekt sollte darauf ausgelegt sein, dieses Problem zu lösen. Es ist grundsätzlich nicht ratsam, auf Biegen und Brechen eine ML Lösung zu implementieren, wenn kein klar definiertes Problem vorliegt. Nehmen Sie sich also zu Beginn eines Projekts Zeit, das Problem grundlegend zu definieren. Sprechen Sie auch mit den entsprechenden Fachexpert*innen im Unternehmen, um genau zu verstehen, verbessert oder effizienter gemacht werden soll und die technischen oder ökonomischen Einschränkungen sind.Sobald das Problemverständnis vorhanden ist, beginnen Sie, sich mit den verfügbaren Daten zu befassen. Auch hier müssen Sie sich wahrscheinlich mit den entsprechenden Expert*innen im Unternehmen (z.B. Datenbankadministrator*innen) austauschen. Es geht hier unter anderem darum abzuklären, welche Daten verfügbar sind, welchem Format die Daten vorhanden sind wie die Datenqualität ist.Danach beginnen Sie mit den Datenarbeiten. Häufig wird dieser Schritt Preprocessing oder Data Cleaning genannt. Oft verschlingt dieser Arbeitsschritt sehr viel Zeit und es ist nicht unüblich, dass 80% der Projektzeit hier aufgewendet werden. Es ist auch völlig normal, wenn Sie von diesem Schritt zurück zur Problemdefinition gehen und sie verfeinern oder anpassen müssen oder zum Beispiel nochmals Fragen mit den Datenbankexpert*innen klären müssen, weil Ihr Datenverständnis noch nicht vollständig ist.Nachdem die Daten vorbereitet wurden, gehen Sie typischerweise zu einer explorativen Analyse der Daten über. Das heisst, Sie visualisieren die vorhandenen Variablen univariat (d.h. jede Variable einzeln) oder multivariat (d.h. zwei oder mehr Variablen zusammen). Ein Beispiel einer univariaten Visualisierung ist ein Histogramm einer quantitativen Variable (z.B. Quartalsumsätze). Ein Beispiel einer multivariaten Visualisierung ist ein Streudiagramm zweier quantitativer Variablen (z.B. Quartalsumsätze und Wechselkurse). Auch hier ist es üblich, dass Sie einen Schritt zurück gehen und weitere Datenbereinigungen vornehmen müssen.Nach der explorativen Analyse der Daten sollten Sie eine erste Idee von den wichtigsten Zusammenhängen den Daten haben. Basierend darauf können Sie Ihr erstes Modell wählen und trainieren und mit der eigentlichen Analyse bzw. der Lösung des Problems beginnen.Einer der wichtigsten Schritte ist die saubere und gründliche Evaluation Ihrer Modelle. Dieser Schritt dient einerseits dazu das beste Modell auszuwählen und andererseits dazu die Qualität Ihrer Lösung bzw. Ihres Modells abzuschätzen. Mit diesem zweiten Schritt wollen Sie nämlich bereits während der Projektphase einschätzen können, wie gut Ihr Modell das gegebene Problem löst oder einen bestehenden Betriebsprozess verbessert oder effizienter macht. Die beiden Schritte Analyse und Evaluation werden typischerweise ein paar Mal iteriert, bis Sie das beste Modell gefunden haben.Schluss geht es darum, dass Sie Ihr Wissen und Ihre Erkenntnisse die relevanten Fachexpert*innen weitergeben (Wissenstransfer) und Ihr finales Modell einer produktiven Umgebung implementieren (oft Deployment genannt). Zum Beispiel können Sie Ihr Modell einer mobilen App einbetten oder als REST API Service zur Verfügung stellen.","code":""},{"path":"basics.html","id":"basics","chapter":"2 Mathematik- und Statistik-Grundlagen","heading":"2 Mathematik- und Statistik-Grundlagen","text":"diesem Kapitel repetieren wir die wichtigsten Grundlagen aus der Mathematik und Statistik, die es braucht, um Machine Learning Modelle zu verstehen. Das Thema Lineare Algebra wird für die meisten von Ihnen wahrscheinlich Neuland sein.","code":""},{"path":"basics.html","id":"funktionen","chapter":"2 Mathematik- und Statistik-Grundlagen","heading":"2.1 Funktionen","text":"Eine Funktion, die wir der Mathematik typischerweise mit \\(f\\) bezeichnen, ordnet jedem Argument \\(x\\) aus dem Definitionsbereich \\(D\\) (engl. Domain) genau einen Wert \\(y\\) aus dem Wertebereich \\(W\\) (engl. Codomain) zu. Oft sind \\(D\\) und \\(W\\) die Menge der reellen Zahlen, also \\(\\mathbb{R}\\). Die Menge der reellen Zahlen enthält alle möglichen Zahlen, die Sie sich vorstellen können.8 Zum Beispiel die Zahlen \\(3\\), \\(-4.247\\), \\(\\sqrt{14}\\), \\(5/8\\), etc.Wie eine Funktion grafisch aussieht, ist aus Panel () der Abbildung 2.1 ersichtlich. Hier zeigen wir die Form einer Funktion einem kartesischen Koordinatensystem. Die Funktionskurve weist jedem Wert \\(x\\) auf der x-Achse genau einen Wert \\(y\\) auf der y-Achse zu. Der wichtigste Teil der oben aufgeführten Definition ist der Teil “genau einen Wert”, denn eine Funktion kann einem Element \\(x\\) nicht zwei oder mehr Werte zuweisen, sondern nur genau einen. Genau aus diesem Grund handelt es sich bei Panel (b) Abbildung 2.1 nicht um eine Funktion, da gewissen \\(x\\)-Werten mehrere Werte \\(y\\) zugeordnet werden. Wichtig: das heisst aber nicht, dass zwei verschiedenen \\(x\\)-Werten, nennen wir sie \\(x'\\) und \\(x''\\), derselbe \\(y\\)-Wert zugeordnet werden kann (vgl. Panel ()).\nAbbildung 2.1: () Eine Funktion, die jedem x-Wert genau einen y-Wert zuweist. (b) Keine Funktion.\nMathematisch wird diese allgemeine Definition einer Funktion häufig wie folgt beschrieben:\\[\nf : x \\mapsto y\n\\]\nWir haben also eine Funktion \\(f\\), die jedem Element \\(x\\) genau einen Wert \\(y\\) zuweist. Der Pfeil obiger mathematischer Schreibweise beschreibt genau dieses Mapping. Wie genau dieses Mapping einem Argument \\(x\\) den entsprechenden \\(y\\)-Wert zuordnet, wird durch die Funktion \\(f(x)\\) beschrieben. den folgenden Abschnitten schauen wir uns typische Beispiele von Funktionen , angefangen mit linearen Funktionen. Doch vorher wollen wir uns kurz überlegen, warum Funktionen für das Machine Learning überhaupt wichtig sind. Ein grosser Teil des Machine Learnings, der Supervised Learning genannt wird, befasst sich mit dem Problem, wie eine Zielvariable \\(y\\) mithilfe von einem oder mehreren Prädiktoren \\(x\\) vorhergesagt werden kann. Ein Machine Learning Modell ist darum nichts anderes als eine Funktion \\(y=f(x)\\), die basierend auf den Prädiktoren \\(x\\) die Zielvariable \\(y\\) möglichst gut beschreiben kann.9","code":""},{"path":"basics.html","id":"lineare-funktionen","chapter":"2 Mathematik- und Statistik-Grundlagen","heading":"2.1.1 Lineare Funktionen","text":"Nun schauen wir uns , wie eine lineare Funktion aussieht. Eine lineare Funktion kann allgemein wie folgt geschrieben werden:\\[\ny = f(x) = \\cdot x + b\n\\]\nObige Funktionsgleichung besagt, dass wir den entsprechenden \\(y\\)-Wert kriegen, indem wir den Wert des Arguments \\(x\\) mit \\(\\) multiplizieren und danach eine Konstante \\(b\\) addieren. \\(\\) und \\(b\\) sind die Parameter dieser Funktion. Die konkreten Zahlenwerte dieser beiden Parameter definieren, wie die Funktion Schluss genau aussieht.Eine lineare Funktion hat auch eine geometrische Interpretation und zwar entspricht eine lineare Funktion einer Gerade. Das ist auch der Grund, warum wir diese Funktionen linear nennen, sie können graphisch durch eine “Linie” dargestellt werden. Der Parameter \\(\\) ist die Steigung dieser Geraden und der Parameter \\(b\\) entspricht dem Ort, wo die Gerade die y-Achse schneidet (sogenannter y-Achsenabschnitt).besten schauen wir uns ein paar konkrete Beispiele (Abb. 2.2).\nAbbildung 2.2: Beispiele linearer Funktionen.\nAus der linken Abbildung können wir ablesen, dass die Steigung dieser Geraden \\(\\frac{\\Delta y}{\\Delta x}=\\frac{2}{2}=1\\) ist und dass die Gerade die y-Achse Ort \\(1\\) schneidet. Die entsprechende lineare Funktion kann dementsprechend als \\(y = x + 1\\) geschrieben werden.10Aus der rechten Abbildung können wir ablesen, dass die Steigung \\(\\frac{\\Delta y}{\\Delta x}=\\frac{-1}{2}=-0.5\\) ist und dass die Gerade die y-Achse Ort \\(-2\\) schneidet. Die entsprechende lineare Funktion kann dementsprechend als \\(y = -0.5\\cdot x -2\\) geschrieben werden.Es ist wichtig zu sehen, dass der Effekt einer Veränderung von \\(x\\) (also \\(\\Delta x\\)) auf \\(y\\) überall derselbe ist. Es spielt also keine Rolle, ob wir von \\(x=-2\\) zu \\(x=-1\\) gehen oder von \\(x=100\\) zu \\(x=101\\), die entsprechende Veränderung \\(y\\) (also \\(\\Delta y\\)) wird dieselbe sein. Das muss sein, denn die Gerade steigt (oder sinkt) mit konstanter Steigung.AufgabenZeichnen Sie die Funktion \\(y = 2\\cdot x\\) ein Koordinatensystem ein. Warum fehlt der Parameter \\(b\\)?Zeichnen Sie die Funktion \\(y=-3\\) ein Koordinatensystem ein. Ist das überhaupt eine Funktion nach obiger Definition?","code":""},{"path":"basics.html","id":"quadratische-funktionen","chapter":"2 Mathematik- und Statistik-Grundlagen","heading":"2.1.2 Quadratische Funktionen","text":"Nun wollen wir uns eine etwas interessantere (und flexiblere) Familie von Funktionen anschauen, nämlich quadratische Funktionen. Auch hier wollen wir die Funktion erstmal allgemein aufschreiben:\\[\ny = f(x) = \\cdot x^2 + b \\cdot x + c\n\\]\nEine quadratische Funktion hat drei Parameter, nämlich \\(\\), \\(b\\) und \\(c\\). Grafisch entspricht die quadratische Funktion einer Parabel (vgl. Abb. 2.3). Die Parameter sind hier nicht mehr einfach grafisch zu interpretieren, aber die vier Beispiele unten stehender Abbildung geben Anhaltspunkte, passiert, wenn die Parameterwerte sich ändern.\nAbbildung 2.3: Beispiele quadratischer Funktionen.\nAufgabenSie haben folgende quadratische Gleichung: \\(y = 2 \\cdot x^2 + x - 2\\). Berechnen Sie mit der bekannten Lösungsformel \\(x_{1,2}=\\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\\) die Orte auf der x-Achse, wo die Parabel die Achse schneidet (oder einfacher gesagt die Nullstellen).Verwenden Sie folgenden R-Code, um beliebige quadratische Funktionen grafisch darzustellen, indem Sie die Parameterwerte auf der ersten Code-Zeile verändern.Sie wundern sich nun vielleicht, könnte man nicht auch eine Funktion antreffen, der \\(x^3\\), \\(x^4\\), etc. vorkommen? Das ist selbstverständlich möglich. diesem Fall spricht man dann von einem sogenannten Polynom. Die höchste Potenz des Arguments \\(x\\) definiert den Grad des Polynoms.Schauen wir uns doch besten gleich wieder ein Beispiel :\\[\ny = f(x) = 1 \\cdot x^4 - 2 \\cdot x^3 - 5 \\cdot x^2 + 8 \\cdot x - 2\n\\]\nDie Visualisierung dieser Funktion ist Abb. 2.4 gegeben. Diese Funktion ist nun bereits enorm flexibel und kann je nach Parameterwerten ganz unterschiedliche Zusammenhänge abbilden.\nAbbildung 2.4: Beispiel einer polynomischen Funktion vierten Grades.\nAufgabenEine quadratische Funktion ist ein Polynom welchen Grades?Handelt es sich bei der Funktion \\(y=2x^5 + x + 1\\) immer noch um ein Polynom? Falls ja, ein Polynom welchen Grades?Handelt es sich bei der Funktion \\(y = x^{0.5} + 2\\) um ein Polynom?","code":"\n# Parameter setzen\na <- 2; b <- 0; c <- 1\n# Quadratische Funktion\nquad <- function(x, a, b, c) {a * x^2 + b * x + c}\n# x-Werte\nx <- seq(-6, 6, 0.01)\n# y-Werte\ny <- quad(x, a, b, c)\n# Plot\nplot(x, y, type = \"l\", lwd = 2, col = \"darkcyan\")"},{"path":"basics.html","id":"funktionen-mehrerer-argumente","chapter":"2 Mathematik- und Statistik-Grundlagen","heading":"2.1.3 Funktionen mehrerer Argumente","text":"Bisher haben wir nur Funktionen mit einem Argument \\(x\\) angeschaut, doch die meisten für das Machine Learning interessanten Funktionen sind Funktionen mehrerer Argumente.Der Einfachheit halber schauen wir uns hier nur mal eine lineare Funktion zweier Argumente, nennen wir sie \\(x_1\\) und \\(x_2\\), , denn diese können wir 3D immer noch visualisieren. Wir betrachten folgende Funktion: \\(y = f(x_1,x_2) = 1 \\cdot x_1 + 0.5 \\cdot x_2 + 5\\).\nAbbildung 2.5: Lineare Funktion zweier Argumente (Ebene).\nAha! Während eine lineare Funktion eines Arguments grafisch einer Gerade entspricht, sehen wir nun, dass eine lineare Funktion zweier Argumente nichts anderes als eine Ebene darstellt. Wir sehen, dass die Ebene die y-Achse Punkt \\(5\\) schneidet. Etwas schwieriger zu sehen ist die Steigung der Ebene die Richtung der \\(x_1\\)-Achse und die Richtung der \\(x_2\\)-Achse. Sie können aber vielleicht bereits erraten, dass die (partiellen) Steigungen \\(1\\) und \\(0.5\\) betragen.Die Funktion ordnet jeden möglichen Punkt \\((x_1,x_2)\\) einem Punkt auf der Ebene zu. Wir können zum Beispiel für den Abb. 2.5 eingezeichneten Punkt \\((6,4)\\) den entsprechenden Punkt auf der Ebene ausrechnen:\\[ \\begin{split}\ny &= 1 \\cdot x_1 + 0.5 \\cdot x_2 + 5\\\\\n&= 1 \\cdot 6 + 0.5 \\cdot 4 + 5\\\\\n&= 13\n\\end{split}\\]Selbstverständlich könnten wir uns nun auch quadratische Funktionen oder Polynome mehrerer Argumente anschauen, aber darauf verzichten wir vorerst.","code":""},{"path":"basics.html","id":"potenzen-und-logarithmen","chapter":"2 Mathematik- und Statistik-Grundlagen","heading":"2.1.4 Potenzen und Logarithmen","text":"Blabla…","code":""},{"path":"basics.html","id":"integral--und-differentialrechnung","chapter":"2 Mathematik- und Statistik-Grundlagen","heading":"2.2 Integral- und Differentialrechnung","text":"Olteanu materials:\nLocal vs. global minima\nmaximization minimization problem\nBasic definition derivative\nDifferentiation rules\nlocal min., max. saddle point\nSecond derivative test\nPartial derivatives\ngradient? Hessian? Jacobian?\nChain rules\nLagrange optimization","code":""},{"path":"basics.html","id":"lineare-algebra","chapter":"2 Mathematik- und Statistik-Grundlagen","heading":"2.3 Lineare Algebra","text":"Olteanu materials:\nscalar? vector? matrix?\nVector norms\nInner products\nSymmetric, diagonal, square identity matrix\nAssociative, commutative laws matrices\nMatrix addition multiplication\nMatrix inversion\nEigenvectors eigenvalues\nQuadratic form positive (semi-) definiteness\nDifferentiation rules matrices","code":""},{"path":"basics.html","id":"wahrscheinlichkeitsrechnung","chapter":"2 Mathematik- und Statistik-Grundlagen","heading":"2.4 Wahrscheinlichkeitsrechnung","text":"Olteanu materials:\nSample space axioms probability\nConditional probability definition\nDiscrete vs. continuous random variables\nJoint probability distributions\nExpectation variance, covariance (always discrete continuous)\nBernoulli, Binomial, Normal, Multivariate Normal, Laplace","code":""},{"path":"basics.html","id":"diskrete-zufallsvariablen","chapter":"2 Mathematik- und Statistik-Grundlagen","heading":"2.4.1 Diskrete Zufallsvariablen","text":"Wir werden später sehen, dass im Machine Learning oftmals Dinge als Zufallsvariablen modelliert werden. Eine Zufallsvariable \\(X\\) ist eine Variable, für die der konkrete Wert nicht von vornherein klar ist. Wir können mit \\(X\\) zum Beispiel das Resultat eines Münzwurfs modellieren. Die zwei möglichen Resultate sind Kopf und Zahl. Vor dem Münzwurf ist nicht klar, ob Kopf oder Zahl erscheinen wird. Genau darum modellieren wir das Resultat des Münzwurfs als Zufallsvariable.Es gibt diesem einfachen Beispiel nur zwei mögliche Resultate (Kopf und Zahl), d.h. die Anzahl möglicher Resultate ist endlich (= nicht unendlich). Darum handelt es sich diesem Fall um eine diskrete Zufallsvariable.","code":""},{"path":"basics.html","id":"verteilungen","chapter":"2 Mathematik- und Statistik-Grundlagen","heading":"2.5 Verteilungen","text":"","code":""},{"path":"intro-R.html","id":"intro-R","chapter":"3 Einführung in das Programmieren mit R","heading":"3 Einführung in das Programmieren mit R","text":"leaRn MaterialentidymodelsReferenzen auf andere Ressourcen (Hadley et al.)","code":""},{"path":"lin-reg.html","id":"lin-reg","chapter":"4 Lineare Regression","heading":"4 Lineare Regression","text":"","code":""},{"path":"lin-class.html","id":"lin-class","chapter":"5 Lineare Klassifikation","heading":"5 Lineare Klassifikation","text":"","code":""},{"path":"ml-pipeline.html","id":"ml-pipeline","chapter":"6 Machine Learning Pipeline","heading":"6 Machine Learning Pipeline","text":"","code":""},{"path":"trees.html","id":"trees","chapter":"7 Decision Trees","heading":"7 Decision Trees","text":"","code":""},{"path":"ensembles.html","id":"ensembles","chapter":"8 Ensembles","heading":"8 Ensembles","text":"","code":""},{"path":"svm.html","id":"svm","chapter":"9 Support Vector Machines","heading":"9 Support Vector Machines","text":"","code":""},{"path":"ann.html","id":"ann","chapter":"10 Artificial Neural Networks","heading":"10 Artificial Neural Networks","text":"","code":""},{"path":"cnn.html","id":"cnn","chapter":"11 Convolutional Neural Networks","heading":"11 Convolutional Neural Networks","text":"","code":""},{"path":"rnn.html","id":"rnn","chapter":"12 Recurrent Neural Networks","heading":"12 Recurrent Neural Networks","text":"","code":""},{"path":"gen-AI.html","id":"gen-AI","chapter":"13 Generative AI","heading":"13 Generative AI","text":"","code":""},{"path":"bibliographie.html","id":"bibliographie","chapter":"Bibliographie","heading":"Bibliographie","text":"","code":""}]
