<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>4 Lineare Regression | Machine Learning für das KMU</title>
<meta name="author" content="Martin Sterchi">
<meta name="description" content="In diesem Kapitel werden wir uns eingehend mit dem einfachsten Modell für das Regressionsproblem auseinander setzen, nämlich dem linearen Regressionsmodell. Liegt ein Regressionsproblem vor, dann...">
<meta name="generator" content="bookdown 0.38 with bs4_book()">
<meta property="og:title" content="4 Lineare Regression | Machine Learning für das KMU">
<meta property="og:type" content="book">
<meta property="og:description" content="In diesem Kapitel werden wir uns eingehend mit dem einfachsten Modell für das Regressionsproblem auseinander setzen, nämlich dem linearen Regressionsmodell. Liegt ein Regressionsproblem vor, dann...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="4 Lineare Regression | Machine Learning für das KMU">
<meta name="twitter:description" content="In diesem Kapitel werden wir uns eingehend mit dem einfachsten Modell für das Regressionsproblem auseinander setzen, nämlich dem linearen Regressionsmodell. Liegt ein Regressionsproblem vor, dann...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.6.1/transition.js"></script><script src="libs/bs3compat-0.6.1/tabs.js"></script><script src="libs/bs3compat-0.6.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Machine Learning für das KMU</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Über das Buch</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">1</span> Einführung</a></li>
<li><a class="" href="basics.html"><span class="header-section-number">2</span> Mathematik- und Statistik-Grundlagen</a></li>
<li><a class="" href="intro-R.html"><span class="header-section-number">3</span> Einführung in das Programmieren mit R</a></li>
<li><a class="active" href="lin-reg.html"><span class="header-section-number">4</span> Lineare Regression</a></li>
<li><a class="" href="lin-class.html"><span class="header-section-number">5</span> Lineare Klassifikation</a></li>
<li><a class="" href="ml-pipeline.html"><span class="header-section-number">6</span> Machine Learning Pipeline</a></li>
<li><a class="" href="trees.html"><span class="header-section-number">7</span> Decision Trees</a></li>
<li><a class="" href="ensembles.html"><span class="header-section-number">8</span> Ensembles</a></li>
<li><a class="" href="svm.html"><span class="header-section-number">9</span> Support Vector Machines</a></li>
<li><a class="" href="ann.html"><span class="header-section-number">10</span> Artificial Neural Networks</a></li>
<li><a class="" href="cnn.html"><span class="header-section-number">11</span> Convolutional Neural Networks</a></li>
<li><a class="" href="rnn.html"><span class="header-section-number">12</span> Recurrent Neural Networks</a></li>
<li><a class="" href="gen-AI.html"><span class="header-section-number">13</span> Generative AI</a></li>
<li><a class="" href="bibliographie.html">Bibliographie</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/martinSter/aml-book">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="lin-reg" class="section level1" number="4">
<h1>
<span class="header-section-number">4</span> Lineare Regression<a class="anchor" aria-label="anchor" href="#lin-reg"><i class="fas fa-link"></i></a>
</h1>
<p>In diesem Kapitel werden wir uns eingehend mit dem einfachsten Modell für das Regressionsproblem auseinander setzen, nämlich dem linearen Regressionsmodell. Liegt ein Regressionsproblem vor, dann macht es in der Praxis fast immer Sinn mit diesem Modell zu starten und dann die Komplexität nach Bedarf zu erhöhen.</p>
<div id="ml-modelle-im-allgemeinen" class="section level2" number="4.1">
<h2>
<span class="header-section-number">4.1</span> ML-Modelle im Allgemeinen<a class="anchor" aria-label="anchor" href="#ml-modelle-im-allgemeinen"><i class="fas fa-link"></i></a>
</h2>
<p>Wie bereits in Kapitel <a href="intro.html#intro">1</a> gesehen, geht es beim Regressionsproblem darum, eine stetige Variable <span class="math inline">\(y_i \in \mathbb{R}\)</span> möglichst optimal vorherzusagen. Dazu verwenden wir eine oder mehrere Input-Variablen, welche wir kompakt als Vektor <span class="math inline">\(\mathbf{x}_i\)</span> schreiben.</p>
<p>Das Problem ist nur lösbar, falls es tatsächlich einen Zusammenhang zwischen den Input-Variablen <span class="math inline">\(\mathbf{x}_i\)</span> und dem Output <span class="math inline">\(y_i\)</span> gibt. Wir nehmen ganz allgemein an, dass der Zusammenhang zwischen dem Output <span class="math inline">\(y_i\)</span> und den Input-Variablen <span class="math inline">\(\mathbf{x}_i\)</span> mathematisch wie folgt ausgedrückt werden kann:</p>
<p><span class="math display">\[
y_i = f(\mathbf{x}_i) + \epsilon
\]</span></p>
<ul>
<li>Die Funktion <span class="math inline">\(f(\mathbf{x}_i)\)</span> bezeichnet die <strong>systematische Information</strong>, die wir aus <span class="math inline">\(\mathbf{x}_i\)</span> im Hinblick auf <span class="math inline">\(y_i\)</span> lernen können.</li>
<li>
<span class="math inline">\(\epsilon\)</span> ist ein Fehlerterm, der die Differenz zwischen <span class="math inline">\(y_i\)</span> und <span class="math inline">\(f(\mathbf{x}_i)\)</span> abbildet,<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span class="math inline"&gt;\(\epsilon = y_i - f(\mathbf{x}_i)\)&lt;/span&gt;&lt;/p&gt;'><sup>11</sup></a> also den <strong>nicht-lernbaren</strong> (unsystematischen) <strong>Teil</strong>. Der Fehlerterm beinhaltet einerseits den Effekt von Variablen, die uns nicht zur Verfügung stehen, aber einen Einfluss auf den Output <span class="math inline">\(y_i\)</span> haben und andererseits nicht-messbare Variation, oft auch einfach <em>Noise</em> genannt. Grob gesagt: alles nicht-messbare. Auch wichtig zu sehen: der Fehler ist <strong>additiv</strong>, wir addieren ihn zum lernbaren Teil hinzu.</li>
</ul>
<p>Der Output <span class="math inline">\(y_i\)</span> ergibt sich also aus der Addition eines systematischen Teils <span class="math inline">\(f(\mathbf{x}_i)\)</span> sowie eines Fehlerterms <span class="math inline">\(\epsilon\)</span>.</p>
<div style="background-color:#DEEBF7; padding:10px">
<p><strong>Wichtig</strong>: Ziel des Machine Learnings ist es, eine Funktion <span class="math inline">\(\hat{f}(\mathbf{x}_i)\)</span> zu trainieren (schätzen), die der wahren aber unbekannten Funktion <span class="math inline">\(f(\mathbf{x}_i)\)</span> so nahe wie möglich kommt. Im (unrealistischen) Idealfall ist unser trainiertes Modell gleich der wahren Funktion, also <span class="math inline">\(\hat{f}(\mathbf{x}_i) = f(\mathbf{x}_i)\)</span> und wir haben die systematische Information perfekt gelernt. Jedes ML-Modell, das wir uns in diesem Buch anschauen werden, kann als eine mathematische Funktion <span class="math inline">\(\hat{f}(\mathbf{x}_i)\)</span> der Input-Variablen <span class="math inline">\(\mathbf{x}_i\)</span> aufgeschrieben werden. Sobald wir <span class="math inline">\(\hat{f}(\mathbf{x}_i)\)</span> trainiert haben, können wir damit Vorhersagen machen, denn die Vorhersage für einen gegebenen Input-Vektor <span class="math inline">\(\mathbf{x}_0\)</span> ist nichts anderes als der Wert der trainierten Funktion an diesem Punkt, also <span class="math inline">\(\hat{y}_0 = \hat{f}(\mathbf{x}_0)\)</span>.</p>
</div>
</div>
<div id="das-modell-ausgeschrieben" class="section level2" number="4.2">
<h2>
<span class="header-section-number">4.2</span> Das Modell (ausgeschrieben)<a class="anchor" aria-label="anchor" href="#das-modell-ausgeschrieben"><i class="fas fa-link"></i></a>
</h2>
<p>Nun wollen wir uns konkret mit dem <strong>linearen Regressionsmodell</strong> befassen. Das bedeutet nun nichts anderes, als dass wir die allgemein geschriebene Funktion <span class="math inline">\(f(\mathbf{x}_i)\)</span> durch eine konkrete mathematische Funktion ersetzen. Im Machine Learning ist das der erste wichtige Schritt, nämlich die Modellwahl (engl. <em>Model Selection</em>). Das Modell kann wie folgt geschrieben werden:</p>
<p><span class="math display">\[
f(\mathbf{x}_i) = w_0 + w_1 \cdot x_{i1} + w_2 \cdot x_{i2} + \ldots + w_p \cdot x_{ip}
\]</span>
Wir verzichten hier bewusst darauf, den Hut für <span class="math inline">\(f\)</span> zu schreiben, da es sich lediglich um eine allgemein gültige Funktion handelt und noch nichts geschätzt bzw. trainiert wurde. Dieses Modell bzw. diese Funktion hat sogenannte <strong>Parameter</strong>, die es zu schätzen gilt. Hier sind dies die Parameter <span class="math inline">\(w_0,\; w_1,\; \ldots,\; w_p\)</span>. Wegen der Konstante <span class="math inline">\(w_0\)</span> haben wir immer einen Parameter mehr als es Input-Variablen hat, also <span class="math inline">\(p+1\)</span> Parameter.</p>
<p>Diese Parameter sind die Schlüsselzutat in einem ML-Modell. Wir wollen sie <strong>optimieren</strong>, so dass die trainierte Funktion <span class="math inline">\(\hat{f}(\mathbf{x}_i)\)</span> der wahren Funktion <span class="math inline">\(f(\mathbf{x}_i)\)</span> möglichst nahe kommt.</p>
<p>Wir schauen uns in diesem Kapitel ein ganz einfaches Beispiel an mit nur einer Input-Variable <span class="math inline">\(x_i\)</span>, so dass der Zusammenhang zwischen dem Output <span class="math inline">\(y_i\)</span> und dem Input <span class="math inline">\(x_i\)</span> in 2D dargestellt werden kann. In diesem Zusammenhang spricht man vom <strong>einfachen linearen Regressionsmodell</strong>. Ausserdem haben wir nur vier Beobachtungen, welche in Abbildung <a href="lin-reg.html#fig:simple-reg">4.1</a> in einem Streudiagramm dargestellt werden:</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:simple-reg"></span>
<img src="04-lin-reg_files/figure-html/simple-reg-1.png" alt="Einfaches Regressionsbeispiel." width="70%"><p class="caption">
Abbildung 4.1: Einfaches Regressionsbeispiel. Die vier Beobachtungen werden in einem Streudiagramm dargestellt. Auf der x-Achse ist der Wert der Input-Variable und auf der y-Achse der Wert der Output-Variable ablesbar.
</p>
</div>
</div>
<div id="das-modell-kompakt" class="section level2" number="4.3">
<h2>
<span class="header-section-number">4.3</span> Das Modell (kompakt)<a class="anchor" aria-label="anchor" href="#das-modell-kompakt"><i class="fas fa-link"></i></a>
</h2>
<p>Sie sehen oben, dass es ziemlich umständlich sein kann, das lineare Regressionsmodell aufzuschreiben, insbesondere wenn wir viele Input-Variablen haben. Mithilfe von <strong>Vektoren und Matrizen</strong> können wir das Modell viel kompakter aufschreiben.</p>
<p>Wir haben in Kapitel <a href="intro.html#intro">1</a> bereits gesehen, dass die Input-Variablen für eine Beobachtung <span class="math inline">\(i\)</span> als Spaltenvektor geschrieben werden können. Wir modifizieren diesen Spaltenvektor in einem ersten Schritt, indem wir an erster Stelle eine 1 einfügen,<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;So müssen wir die Konstante &lt;span class="math inline"&gt;\(w_0\)&lt;/span&gt; nicht separat aufschreiben.&lt;/p&gt;'><sup>12</sup></a> also:</p>
<p><span class="math display">\[\mathbf{x}_i=\begin{pmatrix} 1\\ x_{i1} \\ x_{i2} \\ \vdots \\ x_{ip} \end{pmatrix}\]</span></p>
<p>Nun stecken wir die Parameter des Modells ebenfalls in einen Spaltenvektor:</p>
<p><span class="math display">\[\mathbf{w}=\begin{pmatrix} w_0 \\ w_1 \\ w_2 \\ \vdots \\ w_p \end{pmatrix}\]</span></p>
<p>Wir können nun das lineare Regressionsmodell (für die Beobachtung <span class="math inline">\(i\)</span>) als <strong>Skalarprodukt</strong> dieser beiden Vektoren aufschreiben:</p>
<p><span class="math display">\[\begin{align}
f(\mathbf{x}_i) &amp;= \mathbf{w}' \mathbf{x_i}\\
&amp;= \begin{pmatrix} w_0 &amp; w_1 &amp; w_2 &amp; \dots &amp; w_p \end{pmatrix} \begin{pmatrix} 1\\ x_{i1} \\ x_{i2} \\ \vdots \\ x_{ip} \end{pmatrix}\\
&amp;= w_0 \cdot 1 + w_1 \cdot x_{i1} + w_2 \cdot x_{i2} + \dots + w_p \cdot x_{ip}
\end{align}\]</span></p>
<p>Die Form <span class="math inline">\(\mathbf{w}' \mathbf{x_i}\)</span> ist schon ziemlich kompakt, aber es geht noch besser. Wir können nämlich das Modell gleich für alle <span class="math inline">\(n\)</span> Beobachtungen (und nicht nur für die <span class="math inline">\(i\)</span>-te Beobachtung) aufschreiben. Dazu müssen wir die Input-Variablen für jede Beobachtung <span class="math inline">\(i\)</span> in einer Matrix anordnen:</p>
<p><span class="math display">\[
\mathbf{X} = \begin{pmatrix}
1 &amp; x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\
1 &amp; x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p}\\
\vdots &amp; \cdots &amp; \cdots &amp; \ddots &amp; \vdots\\
1 &amp; x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np}\\
\end{pmatrix}
\]</span></p>
<p>Die Matrix <span class="math inline">\(\mathbf{X}\)</span> wird typischerweise <strong>Design Matrix</strong> genannt. Die erste Zeile enthält die Input-Variablen für die erste Beobachtung, die zweite Zeile die Input-Variablen für die zweite Beobachtung, usw. Nun können wir das Modell mithilfe einer Multiplikation zwischen der Design Matrix <span class="math inline">\(\mathbf{X}\)</span> und dem Spaltenvektor <span class="math inline">\(\mathbf{w}\)</span> in einem Schritt für alle Beobachtungen aufschreiben:</p>
<p><span class="math display">\[\begin{align}
f(\mathbf{X}) &amp;= \mathbf{X}\mathbf{w}\\
&amp;= \begin{pmatrix}
1 &amp; x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\
1 &amp; x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p}\\
\vdots &amp; \cdots &amp; \cdots &amp; \ddots &amp; \vdots\\
1 &amp; x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np}\\
\end{pmatrix}\begin{pmatrix} w_0 \\ w_1 \\ w_2 \\ \dots \\ w_p \end{pmatrix}\\
&amp;= \begin{pmatrix}
w_0 \cdot 1 + w_1 \cdot x_{11} + w_2 \cdot x_{12} + \dots + w_p \cdot x_{1p} \\
w_0 \cdot 1 + w_1 \cdot x_{21} + w_2 \cdot x_{22} + \dots + w_p \cdot x_{2p} \\
\cdots \\
w_0 \cdot 1 + w_1 \cdot x_{n1} + w_2 \cdot x_{n2} + \dots + w_p \cdot x_{np}\end{pmatrix}
\end{align}\]</span></p>
<p>Überprüfen wir doch noch kurz die Dimensionen von obigem Matrix-Vektor Produkt. Die Matrix <span class="math inline">\(\mathbf{X}\)</span> hat <span class="math inline">\(n\)</span> Zeilen und <span class="math inline">\(p+1\)</span> Spalten und darum eine Dimensionalität von <span class="math inline">\(n \times (p+1)\)</span>. Der Spaltenvektor <span class="math inline">\(\mathbf{w}\)</span> hat Dimensionalität <span class="math inline">\((p+1) \times 1\)</span>. Das Matrix-Vektor Produkt hat dementsprechend eine Dimensionalität von <span class="math inline">\(n \times 1\)</span>, genau was wir erwarten würden, nämlich einen Vektor mit den Vorhersagen für alle <span class="math inline">\(n\)</span> Beobachtungen.</p>
<p>Für unser einfaches Beispiel kann das Modell wie folgt in Matrixform geschrieben werden:</p>
<p><span class="math display">\[\begin{align}
f(\mathbf{X}) &amp;= \mathbf{X}\mathbf{w}\\
&amp;= \begin{pmatrix}
1 &amp; -4.1 \\
1 &amp; -0.5 \\
1 &amp; 1.4 \\
1 &amp; 4.4 \\
\end{pmatrix}\begin{pmatrix} w_0 \\ w_1 \end{pmatrix}\\
&amp;= \begin{pmatrix}
w_0 \cdot 1 - w_1 \cdot 4.1 \\
w_0 \cdot 1 - w_1 \cdot 0.5 \\
w_0 \cdot 1 + w_1 \cdot 1.4 \\
w_0 \cdot 1 + w_1 \cdot 4.4 \end{pmatrix}
\end{align}\]</span></p>
<p>Warum wir all das tun, werden wir weiter unten sehen. Es wird unser Leben viel einfacher machen! Versuchen Sie diesen Abschnitt hier gut zu verstehen, so dass Sie sobald wie möglich mit der Matrixschreibweise von Modellen vertraut sind.</p>
</div>
<div id="modelltraining" class="section level2" number="4.4">
<h2>
<span class="header-section-number">4.4</span> Modelltraining<a class="anchor" aria-label="anchor" href="#modelltraining"><i class="fas fa-link"></i></a>
</h2>
<p>Wir werden uns hier anschauen, dass für das Training (oft auch <em>Fitting</em> genannt) des linearen Regressionsmodells <strong>zwei verschiedene Perspektiven</strong> eingenommen werden können, welche am Schluss beide zum selben Schluss kommen.</p>
<div id="perspektive-1-funktionsoptimierung" class="section level3" number="4.4.1">
<h3>
<span class="header-section-number">4.4.1</span> Perspektive 1: Funktionsoptimierung<a class="anchor" aria-label="anchor" href="#perspektive-1-funktionsoptimierung"><i class="fas fa-link"></i></a>
</h3>
<p>In der ersten Perspektive behandeln wir das Modelltraining als Optimierungsproblem. Wir wollen nämlich eine sogenannte <strong>Kostenfunktion</strong> (engl. <em>Loss Function</em>) aufstellen, die es danach zu minimieren gilt. Sie werden gleich sehen, dass die Kostenfunktion für das lineare Regressionsmodell von den Modellparameter <span class="math inline">\(w_0,w_1,\dots,w_p\)</span> abhängt. Das Ziel wird also sein, die optimalen Werte für die Modellparameter zu finden, so dass die Kostenfunktion so klein wie möglich ist.</p>
<p>Doch wie sieht denn nun diese Kostenfunktion für das lineare Regressionsmodell konkret aus? Wir werden uns hier der Einfachheit halber nur ein <strong>einfaches lineares Regressionsmodell</strong> mit nur einer Input-Variable <span class="math inline">\(x_i\)</span> anschauen (wie in unserem einfachen Beispiel). Die Kostenfunktion sieht in diesem Fall so aus:</p>
<p><span class="math display">\[
J(\hat{w}_0,\hat{w}_1) = \frac{1}{2n} \sum_{i=1}^{n} \left(y_i - \hat{f}(x_i) \right)^2
\]</span></p>
<p>Sie sehen, dass die Kostenfunktion <span class="math inline">\(J(\hat{w}_0,\hat{w}_1)\)</span> eine Funktion der beiden (trainierten) Modellparameter ist. Vielleicht wundern Sie sich nun, wie diese Kostenfunktion von den Modellparameter abhängt, da diese in obiger Formel ja gar nicht direkt ersichtlich sind. Schreiben wir die Kostenfunktion doch mal etwas um:</p>
<p><span class="math display">\[\begin{align}
J(\hat{w}_0, \hat{w}_1) &amp;= \frac{1}{2n} \sum_{i=1}^{n} \left(y_i - \hat{f}(x_i) \right)^2 \\
&amp;= \frac{1}{2n} \sum_{i=1}^{n} \left(y_i - (\hat{w}_0 + \hat{w}_1 \cdot x_i) \right)^2 \\
&amp;= \frac{1}{2n} \sum_{i=1}^{n} \left(y_i - \hat{w}_0 - \hat{w}_1 \cdot x_i \right)^2 \\
\end{align}\]</span></p>
<p>Nun ist offensichtlich, wie die Kostenfunktion <span class="math inline">\(J\)</span> von den Modellparameter <span class="math inline">\(\hat{w}_0\)</span> und <span class="math inline">\(\hat{w}_1\)</span> abhängt. Im ML gibt es nun viele verschiedene Arten, wie man für die beiden Modellparameter die optimalen Werte findet. Hier ist die Lösung zum Glück einfach, denn es gibt eine sogenannte <strong>analytische Lösung</strong>, d.h. es ist möglich für <span class="math inline">\(\hat{w}_0\)</span> und <span class="math inline">\(\hat{w}_1\)</span> je eine Formel zu finden, die uns erlaubt die optimalen Parameterwerte direkt auszurechnen. Die Herleitung dieser Formeln ist nicht besonders schwierig, denn wir wenden nämlich ein altbekanntes Prinzip aus der Differenzialrechnung an: wir berechnen die erste Ableitung der Funktion nach den Modellparameter, setzen sie gleich Null und lösen nach dem Parameter auf.</p>
<p>Machen wir dies in einem ersten Schritt für <span class="math inline">\(\hat{w}_0\)</span>:</p>
<p><span class="math display">\[\begin{align}
\frac{\partial J(\hat{w}_0, \hat{w}_1)}{\partial \hat{w}_0} &amp;= \frac{1}{2n} \sum_{i=1}^{n} 2 \cdot \left(y_i - \hat{w}_0 - \hat{w}_1 \cdot x_i \right) \cdot (-1) \\
&amp;= -\frac{1}{n} \sum_{i=1}^{n} \left(y_i - \hat{w}_0 - \hat{w}_1 \cdot x_i \right) \\
&amp;= -\frac{1}{n} \sum_{i=1}^{n} y_i +  \frac{1}{n} \sum_{i=1}^{n} \hat{w}_0 + \frac{1}{n} \sum_{i=1}^{n} \hat{w}_1 \cdot x_i \\
&amp;= -\bar{y} + \frac{1}{n} \cdot n \cdot \hat{w}_0 + \hat{w}_1 \cdot \bar{x} \\
&amp;= -\bar{y} + \hat{w}_0 + \hat{w}_1 \cdot \bar{x}
\end{align}\]</span></p>
<p>Nun setzten wir die Ableitung gleich Null und lösen nach <span class="math inline">\(\hat{w}_0\)</span> auf:</p>
<p><span class="math display">\[\begin{align}
-\bar{y} + \hat{w}_0 + \hat{w}_1 \cdot \bar{x} &amp;= 0 \\
\hat{w}_0 &amp;= \bar{y} - \hat{w}_1 \cdot \bar{x}
\end{align}\]</span></p>
<p>Wir sehen, dass die Lösung für <span class="math inline">\(\hat{w}_0\)</span> von den beiden Mittelwerten <span class="math inline">\(\bar{y}\)</span> und <span class="math inline">\(\bar{x}\)</span> sowie von <span class="math inline">\(\hat{w}_1\)</span> abhängt. Suchen wir nun also in einem zweiten Schritt die Lösung für <span class="math inline">\(\hat{w}_1\)</span>:</p>
<p><span class="math display">\[\begin{align}
\frac{\partial J(\hat{w}_0, \hat{w}_1)}{\partial \hat{w}_1} &amp;= \frac{1}{2n} \sum_{i=1}^{n} 2 \cdot \left(y_i - \hat{w}_0 - \hat{w}_1 \cdot x_i \right) \cdot (-x_i) \\
&amp;= -\frac{1}{n} \sum_{i=1}^{n} \left(y_i \cdot x_i - \hat{w}_0 \cdot x_i - \hat{w}_1 \cdot x_i^2 \right) \\
&amp;= -\frac{1}{n} \sum_{i=1}^{n} y_i \cdot x_i + \hat{w}_0 \cdot \frac{1}{n} \sum_{i=1}^{n} x_i + \hat{w}_1 \cdot \frac{1}{n} \sum_{i=1}^{n} x_i^2 \\
&amp;= -\frac{1}{n} \sum_{i=1}^{n} y_i \cdot x_i + \hat{w}_0 \cdot \bar{x} + \hat{w}_1 \cdot \frac{1}{n} \sum_{i=1}^{n} x_i^2 \\
\end{align}\]</span></p>
<p>Nun können wir wiederum die Ableitung gleich Null setzen und für <span class="math inline">\(\hat{w}_0\)</span> setzen wir unsere Lösung von oben ein. Danach lösen wir nach <span class="math inline">\(\hat{w}_1\)</span> auf:</p>
<p><span class="math display">\[\begin{align}
-\frac{1}{n} \sum_{i=1}^{n} y_i \cdot x_i + \hat{w}_0 \cdot \bar{x} + \hat{w}_1 \cdot \frac{1}{n} \sum_{i=1}^{n} x_i^2 &amp;= 0 \\
(\bar{y} - \hat{w}_1 \cdot \bar{x}) \cdot \bar{x} + \hat{w}_1 \cdot \frac{1}{n} \sum_{i=1}^{n} x_i^2 &amp;= \frac{1}{n} \sum_{i=1}^{n} y_i \cdot x_i \\
\bar{y} \cdot \bar{x} - \hat{w}_1 \cdot \bar{x}^2 + \hat{w}_1 \cdot \frac{1}{n} \sum_{i=1}^{n} x_i^2 &amp;= \frac{1}{n} \sum_{i=1}^{n} y_i \cdot x_i \\
\hat{w}_1 \left(\frac{1}{n} \sum_{i=1}^{n} x_i^2 - \bar{x}^2 \right) &amp;= \frac{1}{n} \sum_{i=1}^{n} y_i \cdot x_i - \bar{y} \cdot \bar{x} \\
\hat{w}_1 &amp;= \frac{\frac{1}{n} \sum_{i=1}^{n} y_i \cdot x_i - \bar{y} \cdot \bar{x}}{\frac{1}{n} \sum_{i=1}^{n} x_i^2 - \bar{x}^2}
\end{align}\]</span></p>
<p>Vielleicht erkennen Sie die Ausdrücke im Zähler und Nenner der Lösung für <span class="math inline">\(\hat{w}_1\)</span>: es sind dies die <strong>Kovarianz</strong> zwischen <span class="math inline">\(y_i\)</span> und <span class="math inline">\(x_i\)</span> im Zähler und die <strong>Varianz</strong> von <span class="math inline">\(x_i\)</span> im Nenner.</p>
<p>Yay! Nun haben wir die Formeln für die Berechnung der optimalen Parameterwerte des einfachen linearen Regressionsmodells gefunden. Diese Methode wird <strong>Kleinstquadratemethode</strong> (engl. <em>Least Squares</em>) genannt, weil die optimalen Parameter die Summe über die <strong>quadrierten</strong> Differenzen zwischen <span class="math inline">\(y_i\)</span> und den Vorhersagen <span class="math inline">\(\hat{f}(x_i)\)</span> minimieren.</p>
<div class="rmdtip">
<p><strong>Aufgabe</strong></p>
<pre><code>#&gt; Warning: `includeHTML()` was provided a `path` that appears to be a complete HTML document.
#&gt; ✖ Path: exercises/simplelinreg.html
#&gt; ℹ Use `tags$iframe()` to include an HTML document. You can either ensure `path` is accessible in your app or document (see e.g. `shiny::addResourcePath()`) and pass the relative path to the `src` argument. Or you can read the contents of `path` and pass the contents to `srcdoc`.</code></pre>




<style type="text/css">

.collapsible {
  background-color: #065535;
  color: white;
  cursor: pointer;
  padding: 18px;
  width: 100%;
  border: none;
  text-align: left;
  outline: none;
}

.content {
  padding: 0 18px;
  display: none;
  overflow: hidden;
  background-color: #f1f1f1;
}

</style>
<meta charset="utf-8">
<script type="text/javascript" src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script><p>Rechnen Sie nun die optimalen Parameterwerte für unser einfaches lineares Regressionsmodell aus. Sie können die verschiedenen statistischen Grössen entweder mithilfe von R rechnen oder von Hand bzw. mit dem Taschenrechner.</p>

<button type="button" class="collapsible">Lösung</button>
<div class="content">
<br><p>Wir rechnen als erstes die Mittelwerte für die beiden Variablen:</p>
<p><span class="math display">\[
\bar{x} = \frac{-4.1 + (-0.5) + 1.4 + 4.4}{4} = 0.3
\]</span></p>
<p><span class="math display">\[
\bar{y} = \frac{3.50 + 1.95 + (-2.50) + (-2.05)}{4} = 0.225
\]</span></p>
<p>Danach rechnen wir die mittlere Summe über die Produkte der jeweiligen Variablenwerte (erster Teil des Zählers der Formel für <span class="math inline">\(\hat{w}_1\)</span>):</p>
<p><span class="math display">\[
\frac{3.50 \cdot (-4.1) + 1.95 \cdot (-0.5) + (-2.50) \cdot 1.4 + (-2.05) \cdot 4.4}{4} = -6.96125
\]</span></p>
<p>Nun rechnen wir die mittlere Summe über die quadrierten x-Werte (erster Teil des Nenners der Formel für <span class="math inline">\(\hat{w}_1\)</span>):</p>
<p><span class="math display">\[
\frac{(-4.1)^2 + (-0.5)^2 + 1.4^2 + 4.4^2}{4} = 9.595
\]</span></p>
<p>Nun können wir den optimalen Parameterwert für <span class="math inline">\(\hat{w}_1\)</span> berechnen:</p>
<p><span class="math display">\[
\hat{w}_1 = \frac{-6.96125 - 0.225 \cdot 0.3}{9.595 - 0.3^2} = -0.7395
\]</span></p>
<p>Und nun haben wir auch gleich alle Zutaten, um den optimalen Parameterwert für <span class="math inline">\(\hat{w}_0\)</span> zu berechnen:</p>
<p><span class="math display">\[
\hat{w}_0 = 0.225 - (-0.7395) \cdot 0.3 = 0.4469
\]</span></p>
<p>Unser trainiertes optimale Modell sieht also wie folgt aus:</p>
<p><span class="math display">\[
\hat{f}(x_i) = 0.4469 - 0.7395 \cdot x_i
\]</span></p>
</div>
<br>
</div>
<p>Das in der obigen Aufgabe berechnete Modell ist in Abbildung <a href="lin-reg.html#fig:simple-reg-cost">4.2</a> (links) grafisch als blaue Gerade dargestellt. Der Parameter <span class="math inline">\(\hat{w}_0\)</span> ist der Ort, an dem die Gerade die y-Achse durchkreuzt, während der Parameter <span class="math inline">\(\hat{w}_1\)</span> der Steigung der Geraden entspricht. Unser optimales Modell minimiert die Summe über die quadrierten Differenzen zwischen den tatsächlichen <span class="math inline">\(y_i\)</span> Werten und den Vorhersagen gemäss unserem Modell <span class="math inline">\(\hat{f}(x_i)\)</span> (als rot gestrichelte Linien dargestellt).</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:simple-reg-cost"></span>
<img src="04-lin-reg_files/figure-html/simple-reg-cost-1.png" alt="Einfaches Regressionsbeispiel." width="50%"><img src="04-lin-reg_files/figure-html/simple-reg-cost-2.png" alt="Einfaches Regressionsbeispiel." width="50%"><p class="caption">
Abbildung 4.2: Einfaches Regressionsbeispiel. Das geschätzte Modell ist als blaue Gerade eingezeichnet. Die vertikalen roten Linien stellen die Abweichungen der wahren Outputs von den Vorhersagen dar. Rechts ist ein Konturplot der Kostenfunktion mit der optimalen Parameterwert-Kombination dargestellt.
</p>
</div>
<p>Die Abbildung <a href="lin-reg.html#fig:simple-reg-cost">4.2</a> (rechts) zeigt sogennante <strong>Konturlinien</strong> unserer Kostenfunktion. Die optimale Parameterwert-Kombination ist als roter Punkt eingezeichnet. Jede Konturlinie zeigt alle Parameterwert-Kombination, welche jeweils zum gleichen Kostenwert führen. Die fünf eingezeichneten Linien zeigen beispielsweise die Parameterwert-Kombination für die Kostenwerte 1 bis 5 (von innen nach aussen). Man kann sich unsere Kostenfunktion also wie eine Schüssel vorstellen mit dem roten Punkt als Boden der Schüssel. Es handelt sich bei unserer Kostenfunktion um eine Funktion, die <strong>quadratisch</strong> in den Parameterwerten <span class="math inline">\(\hat{w}_0\)</span> und <span class="math inline">\(\hat{w}_1\)</span> ist. In diesem Fall finden wir immer <strong>genau eine Parameterwert-Kombination</strong>, welche dem absoluten Minimum der Kostenfunktion entspricht. Manchmal spricht man auch von einer <strong>konvexen</strong> Kostenfunktion.</p>
<div style="background-color:#fef9e7; padding:10px">
<p><strong>Optional: Kleinstquadratemethode in Matrixform</strong></p>
<p>Die obige Herleitung funktioniert nur für das einfache lineare Regressionsmodell mit einer Input-Variable <span class="math inline">\(x_i\)</span>. Wir schauen uns hier nun kurz die allgemeine Lösung in Matrixform an. Wir nehmen an, dass die Werte unseres Outputs alle in einem Spaltenvektor <span class="math inline">\(\mathbf{y}\)</span> organisiert sind und unsere Modellvorhersagen als <span class="math inline">\(\mathbf{X}\mathbf{\hat{w}}\)</span> geschrieben werden können.</p>
<p>Dann können wir unsere Kostenfunktion von oben wie folgt in Matrixform schreiben:</p>
<p><span class="math display">\[\begin{align}
J(\mathbf{\hat{w}}) &amp;= \frac{1}{2n} (\mathbf{y} - \mathbf{X}\mathbf{\hat{w}})' (\mathbf{y} - \mathbf{X}\mathbf{\hat{w}})
\end{align}\]</span></p>
<p>Das sieht schlimmer aus als es ist, denn <span class="math inline">\((\mathbf{y} - \mathbf{X}\mathbf{\hat{w}})\)</span> ist lediglich ein Spaltenvektor mit den Differenzen zwischen den wahren <span class="math inline">\(y_i\)</span> und den Vorhersagen unseres Modells. Wenn wir diesen Spaltenvektor <span class="math inline">\(\mathbf{e}\)</span> nennen, dann kann obiger Ausdruck als <span class="math inline">\(\frac{1}{2n} \mathbf{e}'\mathbf{e}\)</span> geschrieben werden, wobei <span class="math inline">\(\mathbf{e}'\mathbf{e}\)</span> ein Skalarprodukt ist und dementsprechend einen Skalar bzw. eine einzige Zahl zurück gibt. Diese Zahl multipliziert mit <span class="math inline">\(\frac{1}{2n}\)</span> ist dann nichts anderes als der Wert unserer Kostenfunktion. Sie sehen also, dass wir mit dem Skalarprodukt <span class="math inline">\(\mathbf{e}'\mathbf{e}\)</span> die Summe ersetzen können.</p>
<p>Nun wenden wir die bekannten Matrix-Rechenregeln an, um die Kostenfunktion umzuschreiben:</p>
<p><span class="math display">\[\begin{align}
J(\mathbf{\hat{w}}) &amp;= \frac{1}{2n} (\mathbf{y} - \mathbf{X}\mathbf{\hat{w}})' (\mathbf{y} - \mathbf{X}\mathbf{\hat{w}}) \\
&amp;= \frac{1}{2n} (\mathbf{y}' - \mathbf{\hat{w}}' \mathbf{X}') (\mathbf{y} - \mathbf{X}\mathbf{\hat{w}}) \\
&amp;= \frac{1}{2n} (\mathbf{y}'\mathbf{y} - \mathbf{y}'\mathbf{X}\mathbf{\hat{w}} - \mathbf{\hat{w}}' \mathbf{X}'\mathbf{y} + \mathbf{\hat{w}}' \mathbf{X}'\mathbf{X}\mathbf{\hat{w}})
\end{align}\]</span></p>
<p>Wenn Sie sich kurz anhand der Dimensionalität der einzelnen Komponenten überlegen, was das Endprodukt des Ausdrucks <span class="math inline">\(\mathbf{y}'\mathbf{X}\mathbf{\hat{w}}\)</span> ist, dann werden Sie sehen, dass ein Skalar (Dimensionalität <span class="math inline">\(1 \times 1\)</span>) resultiert. Darum muss zwingend auch die transponierte Form davon, <span class="math inline">\((\mathbf{y}'\mathbf{X}\mathbf{\hat{w}})'=\mathbf{\hat{w}}' \mathbf{X}'\mathbf{y}\)</span> ein Skalar sein, was dazu führt, dass die beiden mittleren Terme in der letzten Zeile von obiger Kostenfunktion identisch sein müssen. Deshalb können wir die Kostenfunktion wie folgt umschreiben:</p>
<p><span class="math display">\[\begin{align}
J(\mathbf{\hat{w}}) &amp;= \frac{1}{2n} (\mathbf{y}'\mathbf{y} - 2\mathbf{y}'\mathbf{X}\mathbf{\hat{w}} + \mathbf{\hat{w}}' \mathbf{X}'\mathbf{X}\mathbf{\hat{w}})
\end{align}\]</span></p>
<p>So, nun können wir die Kostenfunktion nach dem Spaltenvektor mit den Modellparameter <span class="math inline">\(\mathbf{\hat{w}}\)</span> ableiten. Man spricht in diesem Fall nun nicht von einer Ableitung, sondern von einem <strong>Gradienten</strong>. Auch die mathematische Schreibweise ist etwas anders:</p>
<p><span class="math display">\[\begin{align}
\nabla_{\mathbf{\hat{w}}} J(\mathbf{\hat{w}}) &amp;= \frac{1}{2n} (- 2\mathbf{X}'\mathbf{y} + 2\mathbf{X}'\mathbf{X}\mathbf{\hat{w}}) \\
&amp;= \frac{1}{n} (-\mathbf{X}'\mathbf{y} + \mathbf{X}'\mathbf{X}\mathbf{\hat{w}})
\end{align}\]</span></p>
<p>Diesen Ausdruck können wir nun wie gewohnt gleich Null setzen (wobei wir hier rechts einen Nullvektor <span class="math inline">\(\mathbf{0}\)</span> setzen) und mit den Matrix-Rechenregeln nach <span class="math inline">\(\mathbf{\hat{w}}\)</span> auflösen:</p>
<p><span class="math display">\[\begin{align}
\frac{1}{n} (-\mathbf{X}'\mathbf{y} + \mathbf{X}'\mathbf{X}\mathbf{\hat{w}}) &amp;= \mathbf{0} \\
\mathbf{X}'\mathbf{X}\mathbf{\hat{w}} &amp;= \mathbf{X}'\mathbf{y} \\
\mathbf{\hat{w}} &amp;= (\mathbf{X}'\mathbf{X})^{-1}\mathbf{X}'\mathbf{y}
\end{align}\]</span></p>
<p><strong>Wichtig</strong>: Die Matrix <span class="math inline">\(\mathbf{X}'\mathbf{X}\)</span> hat eine Dimensionalität von <span class="math inline">\((p+1) \times (p+1)\)</span>, ist also quadratisch. Sie ist nur invertierbar, wenn die Design Matrix mehr Zeilen als Spalten hat, also wenn <span class="math inline">\(n &gt; (p+1)\)</span>.</p>
</div>
</div>
<div id="perspektive-2-wahrscheinlichkeitstheorie" class="section level3" number="4.4.2">
<h3>
<span class="header-section-number">4.4.2</span> Perspektive 2: Wahrscheinlichkeitstheorie<a class="anchor" aria-label="anchor" href="#perspektive-2-wahrscheinlichkeitstheorie"><i class="fas fa-link"></i></a>
</h3>
<p>Nun werden wir sehen, dass wir die Lösung oben (aus Perspektive 1) auch mit einer probabilistischen Sicht auf die Dinge erhalten. Dazu schreiben wir nochmals kurz den allgemein angenommenen Zusammenhang zwischen dem wahren Output <span class="math inline">\(y_i\)</span> und den Input-Variablen auf und konkretisieren ihn dann gleich für das lineare Regressionsmodell:</p>
<p><span class="math display">\[\begin{align}
y_i &amp;= f(\mathbf{x}_i) + \epsilon \\
&amp;= \mathbf{w}' \mathbf{x_i} + \epsilon \\
\end{align}\]</span></p>
<p>Nun nehmen wir an, dass der Fehlerterm <span class="math inline">\(\epsilon\)</span> normalverteilt ist mit Mittelwert 0 und Varianz <span class="math inline">\(\sigma^2\)</span>, also <span class="math inline">\(\epsilon \sim N(0,\sigma^2)\)</span>. Weil wir annehmen, dass <span class="math inline">\(\mathbf{w}' \mathbf{x_i}\)</span> fix ist (also keine Zufallsvariable), ist unser Output <span class="math inline">\(y_i\)</span> normalverteilt mit Mittelwert <span class="math inline">\(\mathbf{w}' \mathbf{x_i}\)</span> und Varianz <span class="math inline">\(\sigma^2\)</span>:</p>
<p><span class="math display">\[
y_i \sim \mathcal{N}\left(\mathbf{w}' \mathbf{x_i}, \sigma^2\right)
\]</span></p>
<p>Grafisch zeigen!</p>
<p>Nun möchten wir wissen, was die <strong>gemeinsame Verteilung</strong> aller Output-Werte in unserem Datensatz ist. D.h. wie sieht die Wahrscheinlichkeit <span class="math inline">\(p(y_1,y_2,\dots,y_n|\mathbf{w},\mathbf{X},\sigma^2)\)</span> aus? Weil wir annehmen, dass alle Beobachtungen <span class="math inline">\(i\)</span> in unserem Datensatz unabhängig sind, sieht die Antwort auf die Frage folgendermassen aus:</p>
<p><span class="math display">\[
p(y_1,y_2,\dots,y_n|\mathbf{w},\mathbf{X},\sigma^2) = \prod_{i=1}^n \mathcal{N}\left(\mathbf{w}' \mathbf{x_i}, \sigma^2\right)
\]</span></p>
<div style="background-color:#DEEBF7; padding:10px">
<p><strong>Maximum Likelihood</strong></p>
<p>Die gemeinsame Wahrscheinlichkeit <span class="math inline">\(p(y_1,y_2,\dots,y_n)\)</span> wird in der Fachsprache <strong>Likelihood</strong> genannt. Die zentrale Idee hier ist, dass wir die Modellparameter <span class="math inline">\(\mathbf{w}\)</span> so wählen, dass die <em>Likelihood</em> maximal wird. Der daraus folgende Ausdruck für <span class="math inline">\(\mathbf{w}\)</span> wird <strong>Maximum Likelihood</strong> Schätzer genannt und oft als ML abgekürzt, was sehr verwirrlich sein kann, da wir ja auch Machine Learning so abkürzen.</p>
</div>
<p><br></p>
<p>Wir können nun in der Likelihood oben anstelle von <span class="math inline">\(\mathcal{N}\left(\mathbf{w}' \mathbf{x_i}, \sigma^2\right)\)</span> jeweils die Dichtefunktion der Normalverteilung einsetzen:</p>
<p><span class="math display">\[\begin{align}
p(y_1,y_2,\dots,y_n|\mathbf{w},\mathbf{X},\sigma^2) &amp;= \prod_{i=1}^n \mathcal{N}\left(\mathbf{w}' \mathbf{x_i}, \sigma^2\right) \\
&amp;= \prod_{i=1}^n \frac{1}{\sigma\sqrt{2\pi}} \exp\left( -\frac{1}{2}\left(\frac{y_i - \mathbf{w}' \mathbf{x_i}}{\sigma}\right)^{\!2}\,\right)
\end{align}\]</span></p>
<p>Nun vollziehen wir einen kleinen mathematischen Trick, der vielfach angewendet wird: anstelle der <em>Likelihood</em> verwenden wir nun den natürlichen Logarithmus der <em>Likelihood</em> (<em>Log-Likelihood</em>). Das ist möglich, weil sich so das Optimierungsproblem nicht verändert. Das Logarithmieren vereinfacht das Problem ungemein, denn der Logarithmus eines Produkts wird zu einer Summe der logarithmierten Elemente:</p>
<p><span class="math display">\[\begin{align}
\text{ln}\; p(y_1,y_2,\dots,y_n|\mathbf{w},\mathbf{X},\sigma^2) &amp;= \text{ln}\left(\prod_{i=1}^n \frac{1}{\sigma\sqrt{2\pi}} \exp\left( -\frac{1}{2}\left(\frac{y_i - \mathbf{w}' \mathbf{x_i}}{\sigma}\right)^{\!2}\,\right)\right) \\
&amp;= \sum_{i=1}^n \text{ln}\left(\frac{1}{\sigma\sqrt{2\pi}} \exp\left( -\frac{1}{2}\left(\frac{y_i - \mathbf{w}' \mathbf{x_i}}{\sigma}\right)^{\!2}\,\right) \right) \\
&amp;= \sum_{i=1}^n \text{ln}\left(1\right) - \text{ln}\left(\sigma\sqrt{2\pi}\right) - \frac{1}{2}\left(\frac{y_i - \mathbf{w}' \mathbf{x_i}}{\sigma}\right)^{\!2} \\
&amp;= \sum_{i=1}^n \text{ln}\left(1\right) - \sum_{i=1}^n \text{ln}\left(\sigma\sqrt{2\pi}\right) - \sum_{i=1}^n \frac{1}{2}\left(\frac{y_i - \mathbf{w}' \mathbf{x_i}}{\sigma}\right)^{\!2} \\
&amp;= n \cdot \text{ln}\left(1\right) - n \cdot \text{ln}\left(\sigma\sqrt{2\pi}\right) - \frac{1}{2\sigma^2} \sum_{i=1}^n \left(y_i - \mathbf{w}' \mathbf{x_i}\right)^{\!2}
\end{align}\]</span></p>
<p>Wow, nun haben wir ein tolles Resultat gefunden: je kleiner der Term <span class="math inline">\(\sum_{i=1}^n \left(y_i - \mathbf{w}' \mathbf{x_i}\right)^{\!2}\)</span> in obiger Gleichung, desto grösser ist der natürliche Logarithmus der <em>Likelihood</em>. Das heisst nichts anderes, als dass die Kleinstquadratemethode auch der <em>Maximum Likelihood</em> Schätzer ist.</p>
<p>Wir haben diesen Abschnitt damit begonnen anzunehmen, dass unser Output <span class="math inline">\(y_i\)</span> normalverteilt ist, d.h. <span class="math inline">\(y_i \sim \mathcal{N}\left(\mathbf{w}' \mathbf{x_i}, \sigma^2\right)\)</span>. Wir haben nun herausgefunden, dass wir den Spaltenvektor mit den Parameter mit der Kleinstquadratemethode berechnen können. Um die Normalverteilung vollkommen zu spezifizieren, benötigen wir nun noch eine Formel, um die Varianz <span class="math inline">\(\sigma^2\)</span> zu rechnen. Dazu leiten wir den obigen Ausdruck der <em>Log-Likelihood</em> nach <span class="math inline">\(\sigma\)</span> ab:</p>
<p><span class="math display">\[\begin{align}
\frac{\partial \text{ln}\; p(y_1,y_2,\dots,y_n|\mathbf{w},\mathbf{X},\sigma^2)}{\partial \sigma} &amp;= -n\cdot \frac{\sqrt{2\pi}}{\sigma\sqrt{2\pi}} - (-\frac{2}{\sigma^3}) \cdot \frac{1}{2} \sum_{i=1}^n \left(y_i - \mathbf{w}' \mathbf{x_i}\right)^{\!2} \\
&amp;= -\frac{n}{\sigma} + \frac{1}{\sigma^3} \sum_{i=1}^n \left(y_i - \mathbf{w}' \mathbf{x_i}\right)^{\!2}
\end{align}\]</span></p>
<p>Nun können wir wie gewohnt die Ableitung gleich Null setzen und nach <span class="math inline">\(\sigma\)</span> auflösen:</p>
<p><span class="math display">\[\begin{align}
-\frac{n}{\hat{\sigma}} + \frac{1}{\hat{\sigma}^3} \sum_{i=1}^n \left(y_i - \mathbf{\hat{w}}' \mathbf{x_i}\right)^{\!2} &amp;= 0 \\
\frac{n}{\hat{\sigma}} &amp;= \frac{1}{\hat{\sigma}^3} \sum_{i=1}^n \left(y_i - \mathbf{\hat{w}}' \mathbf{x_i}\right)^{\!2} \\
\frac{\hat{\sigma}^3}{\hat{\sigma}} &amp;= \frac{1}{n} \sum_{i=1}^n \left(y_i - \mathbf{\hat{w}}' \mathbf{x_i}\right)^{\!2} \\
\hat{\sigma}^2 &amp;= \frac{1}{n} \sum_{i=1}^n \left(y_i - \mathbf{\hat{w}}' \mathbf{x_i}\right)^{\!2} \\
\end{align}\]</span></p>
<p>Sehr schön, dieses Resultat macht ebenfalls viel Sinn. Die geschätzte Varianz <span class="math inline">\(\hat{\sigma}^2\)</span> ist nichts anderes als der durchschnittliche quadrierte Fehler (engl. <em>Mean Squared Error</em>).</p>
<div class="rmdtip">
<p><strong>Aufgabe</strong></p>
<p>Berechnen Sie …</p>
</div>
</div>
</div>
<div id="regularisierte-regression" class="section level2" number="4.5">
<h2>
<span class="header-section-number">4.5</span> Regularisierte Regression<a class="anchor" aria-label="anchor" href="#regularisierte-regression"><i class="fas fa-link"></i></a>
</h2>
<!-- Kurz auf Variable Selection (siehe ISLR) eingehen. -->
<p>Das zentrale Problem der oben kennen gelernten Kleinstquadratemethode ist, dass sie extrem anfällig auf <strong>Overfitting</strong> ist. Beim linearen Regressionsmodell ist Overfitting vor allem dann ein Problem, wenn die Anzahl Input-Variablen <span class="math inline">\(p\)</span> relativ gross ist im Vergleich zur Anzahl Beobachtungen <span class="math inline">\(n\)</span>. Im Extremfall haben wir mehr Input-Variablen als Beobachtungen (<span class="math inline">\((p+1)&gt;n\)</span>), was dazu führt, dass der Kleinstquadrateschätzer mathematisch nicht rechenbar ist, weil <span class="math inline">\(\mathbf{X}'\mathbf{X}\)</span> nicht invertierbar ist. Das sollte auch intuitiv Sinn machen, denn wie soll eine Schätzung funktionieren, wenn wir im Schnitt weniger als eine Beobachtung pro zu schätzenden Parameter haben.</p>
<p>Wir können das Problem des Overfittings weitgehend lösen, indem wir ein <strong>regularisiertes</strong> Regressionsmodell rechnen. Regularisierung bedeutet eigentlich nichts anderes, als dass wir die ursprüngliche Kostenfunktion für das lineare Regressionsmodell modifizieren. Dabei gibt es zwei bekannte Regularisierungsarten, nämlich <strong>Ridge</strong> oder <strong>LASSO</strong>. Wir fokussieren in einem ersten Schritt auf die Ridge Regularisierung, weil wir in diesem Fall nach wie vor eine analytische Lösung finden.</p>
<div id="ridge-regressionsmodell" class="section level3" number="4.5.1">
<h3>
<span class="header-section-number">4.5.1</span> Ridge Regressionsmodell<a class="anchor" aria-label="anchor" href="#ridge-regressionsmodell"><i class="fas fa-link"></i></a>
</h3>
<p>Die Kostenfunktion für das Ridge Regressionsmodell sieht wie folgt aus:</p>
<p><span class="math display">\[
J(\mathbf{w}) = \frac{1}{2n} \sum_{i=1}^{n} \left(y_i - \hat{f}(\mathbf{x}_i) \right)^2 + \frac{\lambda}{2} \cdot \sum_{j=1}^p w_j^2
\]</span></p>
<p>Diese modifizierte Kostenfunktion hat etwas Erklärungsbedarf:</p>
<ul>
<li>Wir versuchen hier Modellparameter <span class="math inline">\(\mathbf{w}\)</span> zu finden, welche <strong>gleichzeitig</strong> den durchschnittlichen quadrierten Fehler sowie eine Summe über die quadrierten Modellparameter so klein wie möglich machen. Das sind zwei <strong>konkurrenzierende Ziele</strong> und während des Modelltrainings muss der beste Tradeoff gefunden werden.</li>
<li>Der Regularisierungsterm ist eine Summe über die quadrierten Modellparameter. Das Quadrieren stellt sicher, dass sich positive und negative Parameterwerte nicht gegenseitig kompensieren.</li>
<li>Der <strong>Hyperparameter</strong> <span class="math inline">\(\lambda\)</span> legt fest, wie viel (relatives) Gewicht der Regularisierungsterm im Verhältnis zum durchschnittlichen quadrierten Fehler bekommt. Je grösser <span class="math inline">\(\lambda\)</span>, desto stärker “bestrafen” wir komplexe Modelle. Wir werden später sehen, wir wir den optimalen Wert für <span class="math inline">\(\lambda\)</span> via <strong>Cross-Validation</strong> finden können.</li>
<li>Der Regularisierungsterm enthält die Konstante <span class="math inline">\(w_0\)</span> <strong>nicht</strong> (Summe startet bei <span class="math inline">\(j=1\)</span> und nicht bei <span class="math inline">\(j=0\)</span>).</li>
</ul>
<div class="rmdtip">
<p><strong>Aufgabe</strong></p>
<ul>
<li>Was passiert wenn <span class="math inline">\(\lambda=0\)</span>?</li>
<li>Was passiert wenn <span class="math inline">\(\lambda \rightarrow \infty\)</span>?</li>
</ul>
</div>
<div class="rmdtip">
<p><strong>Aufgabe</strong></p>
<pre><code>#&gt; Warning: `includeHTML()` was provided a `path` that appears to be a complete HTML document.
#&gt; ✖ Path: exercises/ridgederiv.html
#&gt; ℹ Use `tags$iframe()` to include an HTML document. You can either ensure `path` is accessible in your app or document (see e.g. `shiny::addResourcePath()`) and pass the relative path to the `src` argument. Or you can read the contents of `path` and pass the contents to `srcdoc`.</code></pre>




<style type="text/css">

.collapsible {
  background-color: #065535;
  color: white;
  cursor: pointer;
  padding: 18px;
  width: 100%;
  border: none;
  text-align: left;
  outline: none;
}

.content {
  padding: 0 18px;
  display: none;
  overflow: hidden;
  background-color: #f1f1f1;
}

</style>
<meta charset="utf-8">
<script type="text/javascript" src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script><p>Berechnen Sie hier nun den optimalen Parameter <span class="math inline">\(\hat{w}_1\)</span> für ein einfaches regularisiertes Regressionsmodell mit nur einer <span class="math inline">\(x_i\)</span> Variable.</p>
<p>Leiten Sie dazu die obige Kostenfunktion nach <span class="math inline">\(\hat{w}_1\)</span> ab, setzen Sie sie gleich Null und lösen Sie nach <span class="math inline">\(\hat{w}_1\)</span> auf.</p>
<p>Für <span class="math inline">\(\hat{w}_0\)</span> können Sie die Lösung aus dem unregularisierten Fall einsetzen, also <span class="math inline">\(\hat{w}_0 = \bar{y} - \hat{w}_1 \cdot \bar{x}\)</span>.</p>

<button type="button" class="collapsible">Lösung</button>
<div class="content">
<br><p>Die Kostenfunktion für das einfache regularisierte Modell sieht konkret wie folgt aus:</p>
<p><span class="math display">\[
\begin{align}
J(\hat{w}_0, \hat{w}_1) = \frac{1}{2n} \sum_{i=1}^{n} \left(y_i - \hat{w}_0 - \hat{w}_1 \cdot x_i \right)^2 + \frac{\lambda}{2} \hat{w}_1^2 \\
\end{align}
\]</span></p>
<p>Nun leiten wir diese Kostenfunktion nach <span class="math inline">\(\hat{w}_1\)</span> ab und gehen durch sehr ähnliche Schritte wie im unregularisierten Fall:</p>
<p><span class="math display">\[
\begin{align}
\frac{\partial J(\hat{w}_0, \hat{w}_1)}{\partial \hat{w}_1} &amp;= \frac{1}{2n} \sum_{i=1}^{n} 2 \cdot \left(y_i - \hat{w}_0 - \hat{w}_1 \cdot x_i \right) \cdot (-x_i) + \frac{2\lambda}{2} \hat{w}_1 \\
&amp;= -\frac{1}{n} \sum_{i=1}^{n} \left(y_i x_i - \hat{w}_0 x_i - \hat{w}_1 x_i^2 \right) + \lambda \hat{w}_1 \\
&amp;= -\frac{1}{n} \sum_{i=1}^{n} y_i x_i + \hat{w}_0 \bar{x} + \hat{w}_1 \cdot \frac{1}{n} \sum_{i=1}^{n} x_i^2 + \lambda \hat{w}_1 \\
&amp;= -\frac{1}{n} \sum_{i=1}^{n} y_i x_i + (\bar{y} - \hat{w}_1 \bar{x}) \cdot \bar{x} + \hat{w}_1 \cdot \frac{1}{n} \sum_{i=1}^{n} x_i^2 + \lambda \hat{w}_1 \\
&amp;= -\frac{1}{n} \sum_{i=1}^{n} y_i x_i + \bar{y}\bar{x} - \hat{w}_1 \bar{x}^2 + \hat{w}_1 \cdot \frac{1}{n} \sum_{i=1}^{n} x_i^2 + \lambda \hat{w}_1
\end{align}
\]</span></p>
<p>Nun setzen wir die Ableitung gleich Null und lösen nach <span class="math inline">\(\hat{w}_1\)</span> auf:</p>
<p><span class="math display">\[
\begin{align}
-\frac{1}{n} \sum_{i=1}^{n} y_i x_i + \bar{y}\bar{x} - \hat{w}_1 \bar{x}^2 + \hat{w}_1 \cdot \frac{1}{n} \sum_{i=1}^{n} x_i^2 + \lambda \hat{w}_1 &amp;= 0 \\
- \hat{w}_1 \bar{x}^2 + \hat{w}_1 \cdot \frac{1}{n} \sum_{i=1}^{n} x_i^2 + \lambda \hat{w}_1 &amp;= \frac{1}{n} \sum_{i=1}^{n} y_i x_i - \bar{y}\bar{x} \\
\hat{w}_1 \left(\frac{1}{n} \sum_{i=1}^{n} x_i^2 - \bar{x}^2 + \lambda \right) &amp;= \frac{1}{n} \sum_{i=1}^{n} y_i x_i - \bar{y}\bar{x} \\
\hat{w}_1 &amp;= \frac{\text{Cov}(y,x)}{\text{Var}(x) + \lambda}
\end{align}
\]</span></p>
<p>Ha, das macht ja irgendwie Sinn. Je grösser der Wert für <span class="math inline">\(\lambda\)</span> desto grösser der Nenner und desto stärker wird der trainierte Wert für <span class="math inline">\(\hat{w}_1\)</span> beschränkt.</p>
</div>
<br><script>
var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.display === "block") {
      content.style.display = "none";
    } else {
      content.style.display = "block";
    }
  });
}
</script>
</div>
<div style="background-color:#fef9e7; padding:10px">
<p><strong>Optional: Ridge Regression in Matrixform</strong></p>
<p>Der Einfachheit halber nehmen wir hier an, dass die Outputwerte <span class="math inline">\(y_i\)</span> hier standardisiert<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Formel für die Standardisierung: &lt;span class="math inline"&gt;\(\frac{y_i-\bar{y}}{s_y}\)&lt;/span&gt;&lt;/p&gt;'><sup>13</sup></a> wurden, so dass der Mittelwert über die standardisierten Outputwerte Null ist. So entfällt die Konstante <span class="math inline">\(w_0\)</span> aus dem Modell, was uns die Matrixform für das Ridge Modell erleichtert, denn der Regularisierungsterm soll ja die Konstante nicht enthalten und wenn es diese nicht gibt, dann gibt es keine Probleme.</p>
<p>Wie weiter oben gesehen, können wir die Kostenfunktion für das nicht-regularisierte Modell wie folgt schreiben:</p>
<p><span class="math display">\[\begin{align}
J(\mathbf{\hat{w}}) &amp;= \frac{1}{2n} (\mathbf{y}'\mathbf{y} - 2\mathbf{y}'\mathbf{X}\mathbf{\hat{w}} + \mathbf{\hat{w}}' \mathbf{X}'\mathbf{X}\mathbf{\hat{w}})
\end{align}\]</span></p>
<p>Der Regularisierungsterm kann sehr einfach in Matrixform geschrieben werden, nämlich als Skalarprodukt <span class="math inline">\(\frac{\lambda}{2}\mathbf{\hat{w}}'\mathbf{\hat{w}}\)</span>. Damit kriegen wir folgende Kostenfunktion:</p>
<p><span class="math display">\[\begin{align}
J(\mathbf{\hat{w}}) &amp;= \frac{1}{2n} (\mathbf{y}'\mathbf{y} - 2\mathbf{y}'\mathbf{X}\mathbf{\hat{w}} + \mathbf{\hat{w}}' \mathbf{X}'\mathbf{X}\mathbf{\hat{w}}) + \frac{\lambda}{2}\mathbf{\hat{w}}'\mathbf{\hat{w}}
\end{align}\]</span></p>
<p>Um den Gradienten dieser Kostenfunktion zu finden, gehen wir nun sehr ähnlich wie oben vor:</p>
<p><span class="math display">\[\begin{align}
\nabla_{\mathbf{\hat{w}}} J(\mathbf{\hat{w}}) &amp;= \frac{1}{2n} (- 2\mathbf{X}'\mathbf{y} + 2\mathbf{X}'\mathbf{X}\mathbf{\hat{w}}) + \frac{2\lambda}{2}\mathbf{\hat{w}} \\
&amp;= \frac{1}{n} (-\mathbf{X}'\mathbf{y} + \mathbf{X}'\mathbf{X}\mathbf{\hat{w}}) + \lambda \mathbf{\hat{w}}
\end{align}\]</span></p>
<p>Diesen Ausdruck können wir nun wie gewohnt gleich Null setzen und mit den Matrix-Rechenregeln nach <span class="math inline">\(\mathbf{\hat{w}}\)</span> auflösen:</p>
<p><span class="math display">\[\begin{align}
\frac{1}{n} (-\mathbf{X}'\mathbf{y} + \mathbf{X}'\mathbf{X}\mathbf{\hat{w}}) + \lambda \mathbf{\hat{w}} &amp;= \mathbf{0} \\
\mathbf{X}'\mathbf{X}\mathbf{\hat{w}} + \lambda \mathbf{\hat{w}} &amp;= \mathbf{X}'\mathbf{y} \\
(\mathbf{X}'\mathbf{X} + \lambda \mathbf{I}) \mathbf{\hat{w}} &amp;= \mathbf{X}'\mathbf{y} \\
\mathbf{\hat{w}} &amp;= (\mathbf{X}'\mathbf{X} + \lambda \mathbf{I})^{-1}\mathbf{X}'\mathbf{y} \\
\end{align}\]</span></p>
<p><strong>Wichtig</strong>: <span class="math inline">\((\mathbf{X}'\mathbf{X} + \lambda \mathbf{I})\)</span> ist immer invertierbar, auch wenn <span class="math inline">\(p&gt;n\)</span>. Wir haben nun also ein analytisch lösbares Regressionsmodell gefunden, dass gut gegen Overfitting schützt.</p>
</div>
<p><br></p>
<div style="background-color:#DEEBF7; padding:10px">
<p><strong>Standardisierung der Input-Variablen</strong></p>
<p>Es ist eminent wichtig, dass Sie alle numerischen Input-Variablen vor der Anwendung eines regularisierten Modells standardisieren, so dass alle Variablen auf der selben Skala “leben”. Warum ist das so wichtig? Sie haben gesehen, dass wir beim Ridge Modell die Grösse der Parameter mit dem Regularisierungsterm beschränken. Wenn jedoch die Input-Variablen alle auf unterschiedlichen Skalen “leben”, dann sind die Parameter nur schon deshalb unterschiedlich. Durch die Standardisierung der Input-Variablen erreichen wir, dass die Parametergrössen vergleichbar werden und die Regularisierung so auch korrekt funktioniert.</p>
</div>
<p><br></p>
</div>
<div id="lasso-regressionsmodell" class="section level3" number="4.5.2">
<h3>
<span class="header-section-number">4.5.2</span> LASSO Regressionsmodell<a class="anchor" aria-label="anchor" href="#lasso-regressionsmodell"><i class="fas fa-link"></i></a>
</h3>
<p>Blabla…</p>
</div>
</div>
<div id="bias-variance-tradeoff" class="section level2" number="4.6">
<h2>
<span class="header-section-number">4.6</span> Bias-Variance Tradeoff<a class="anchor" aria-label="anchor" href="#bias-variance-tradeoff"><i class="fas fa-link"></i></a>
</h2>
<p>Wir haben oben bereits gesehen, dass der Hyperparameter <span class="math inline">\(\lambda\)</span> die Komplexität des regularisierten Regressionsmodells bestimmt. Um noch besser zu verstehen, warum diese Komplexität überhaupt wichtig ist, wollen wir uns nun mit einem ganz wichtigen Konzept beschäftigen, nämlich dem <strong>Bias-Variance Tradeoff</strong>. Dieses Konzept kann <em>intuitiv</em> für alle Bereiche des Supervised Learnings angewendet werden. Für das Regressionsproblem können wir diesen Tradeoff jedoch auch <em>mathematisch</em> herleiten und genau das tun wir jetzt hier.</p>
<p>Stellen Sie sich vor, dass wir eine grosse Anzahl Datensätze zur Verfügung haben und mit jedem dieser Datensätze versuchen wir den wahren funktionalen Zusammenhang <span class="math inline">\(f(\mathbf{x}_i)\)</span> möglichst gut mit <span class="math inline">\(\hat{f}(\mathbf{x}_i)\)</span> zu schätzen. Für jeden Datensatz sieht das geschätzte Modell <span class="math inline">\(\hat{f}(\mathbf{x}_i)\)</span> etwas anders aus. Das geschätzte Modell <span class="math inline">\(\hat{f}\)</span> variiert also je nach Datensatz und ist dementsprechend eine <strong>Zufallsvariable</strong>.</p>
<p>Ausserdem treffen wir folgende Annahmen:</p>
<ul>
<li>Von oben wissen wir, dass <span class="math inline">\(y_i = f(\mathbf{x}_i) + \epsilon\)</span> gilt.</li>
<li>Wir nehmen an, dass der Erwartungswert des nicht-lernbaren Teils <span class="math inline">\(\epsilon\)</span> Null ist, also <span class="math inline">\(\mathbb{E}[\epsilon]=0\)</span>.</li>
<li>Allgemeine Regel zur Varianz einer Zufallsvariable: <span class="math inline">\(\text{Var}(\epsilon) = \mathbb{E}[\epsilon^2] - \mathbb{E}[\epsilon]^2 = \mathbb{E}[\epsilon^2] - 0^2 = \mathbb{E}[\epsilon^2]\)</span>.</li>
</ul>
<p>Um den Bias-Variance Tradeoff zu zeigen, leiten wir nun den <strong>Erwartungswert des quadrierten Fehlers</strong> für eine gegebene Testbeobachtung her, die wir als <span class="math inline">\((y_0,\mathbf{x}_0)\)</span> bezeichnen. Dies wäre der durchschnittliche quadrierte Fehler, den wir für diese Beobachtung kriegen würden, wenn wir mit jedem geschätzten Modell (jedes auf einem unterschiedlichen Datensatz trainiert) die Vorhersage für diese Testbeobachtung rechnen würden.</p>
<p>In einem ersten Schritt erweitern wir den quadrierten Fehler, indem wir einmal den wahren Funktionswert an der Stelle <span class="math inline">\(\mathbf{x}_0\)</span> einmal abziehen und einmal hinzuzählen. Zusammen gibt das Null und verändert darum die rechte Seite der Gleichung nicht:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}\left[\left(y_0 - \hat{f}(\mathbf{x}_0)\right)^2\right] &amp;= \mathbb{E}\left[\left(y_0 - f(\mathbf{x}_0) + f(\mathbf{x}_0) - \hat{f}(\mathbf{x}_0)\right)^2\right]
\end{align}\]</span></p>
<p>Nun verwenden wir die bekannte polynomische Expansion <span class="math inline">\((a+b)^2=a^2+2ab+b^2\)</span>, aber hier behandeln wir <span class="math inline">\(y_0 - f(\mathbf{x}_0)\)</span> als <span class="math inline">\(a\)</span> und <span class="math inline">\(f(\mathbf{x}_0) - \hat{f}(\mathbf{x}_0)\)</span> als <span class="math inline">\(b\)</span>. Dadurch kriegen wir folgende Gleichung:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}\left[\left(y_0 - \hat{f}(\mathbf{x}_0)\right)^2\right] &amp;= \mathbb{E}\biggl[\left(y_0 - f(\mathbf{x}_0)\right)^2 \\
&amp;+ 2\left(y_0 - f(\mathbf{x}_0)\right)(f(\mathbf{x}_0) - \hat{f}(\mathbf{x}_0)) \\
&amp;+ (f(\mathbf{x}_0) - \hat{f}(\mathbf{x}_0))^2\biggr]
\end{align}\]</span></p>
<p>Nun wissen wir aus obigen Annahmen, dass der Erwartungswert von <span class="math inline">\(y_0\)</span> folgender ist: <span class="math inline">\(\mathbb{E}[y_0]=\mathbb{E}[f(\mathbf{x}_0) + \epsilon]=f(\mathbf{x}_0)\)</span>. Dadurch entfällt der erste Teil des zweiten Terms, weil <span class="math inline">\(\mathbb{E}[\left(y_0 - f(\mathbf{x}_0)\right)]=f(\mathbf{x}_0) - f(\mathbf{x}_0)=0\)</span>. Dadurch lässt sich das Ganze massiv vereinfachen zu:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}\left[\left(y_0 - \hat{f}(\mathbf{x}_0)\right)^2\right] &amp;= \mathbb{E}\left[\left(y_0 - f(\mathbf{x}_0)\right)^2\right] + \mathbb{E}\left[(f(\mathbf{x}_0) - \hat{f}(\mathbf{x}_0))^2\right]
\end{align}\]</span></p>
<p>Nun setzen wir im ersten Erwartungswert auf der rechten Seite anstelle von <span class="math inline">\(y_0\)</span> den Term <span class="math inline">\(f(\mathbf{x}_0) + \epsilon\)</span> ein und kriegen folgendes:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}\left[\left(y_0 - \hat{f}(\mathbf{x}_0)\right)^2\right] &amp;= \mathbb{E}\left[\left(f(\mathbf{x}_0) + \epsilon - f(\mathbf{x}_0)\right)^2\right] + \mathbb{E}\left[(f(\mathbf{x}_0) - \hat{f}(\mathbf{x}_0))^2\right] \\
&amp;= \mathbb{E}\left[\epsilon^2\right] + \mathbb{E}\left[(f(\mathbf{x}_0) - \hat{f}(\mathbf{x}_0))^2\right] \\
&amp;= \text{Var}(\epsilon) + \mathbb{E}\left[(f(\mathbf{x}_0) - \hat{f}(\mathbf{x}_0))^2\right]
\end{align}\]</span></p>
<p>Das ist schon mal ein erstes wichtiges Zwischenresultat. Der Erwartungswert des quadrierten Fehlers wird eine untere Grenze haben, die genau der Varianz des Noises <span class="math inline">\(\text{Var}(\epsilon)\)</span> entspricht. Diese untere Grenze des erwarteten Fehlers wird dann erreicht, wenn unser geschätztes Modell genau dem wahren entspricht und darum der zweite Term oben entfällt.</p>
<p>Nun wollen wir diesen zweiten Term oben noch etwas weiter aufspalten. Dazu brauchen wir wiederum den Trick, den wir oben bereits angewendet haben. Wir ziehen den Erwartungswert des geschätzten Modells <span class="math inline">\(\mathbb{E}\left[\hat{f}(\mathbf{x}_0)\right]\)</span> einmal ab und fügen ihn einmal hinzu:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}\left[(f(\mathbf{x}_0) - \hat{f}(\mathbf{x}_0))^2\right] &amp;= \mathbb{E}\left[\left(f(\mathbf{x}_0) - \mathbb{E}\left[\hat{f}(\mathbf{x}_0)\right] + \mathbb{E}\left[\hat{f}(\mathbf{x}_0)\right] - \hat{f}(\mathbf{x}_0)\right)^2\right] \\
&amp;= \mathbb{E}\left[\left(f(\mathbf{x}_0) - \mathbb{E}\left[\hat{f}(\mathbf{x}_0)\right] - \left(\hat{f}(\mathbf{x}_0) - \mathbb{E}\left[\hat{f}(\mathbf{x}_0)\right]\right)\right)^2\right]
\end{align}\]</span></p>
<p>Ähnlich wie weiter oben können wir diese Gleichung mit einer polynomischen Expansion wie folgt umschreiben:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}\left[(f(\mathbf{x}_0) - \hat{f}(\mathbf{x}_0))^2\right] &amp;= \mathbb{E}\biggl[\left(f(\mathbf{x}_0) - \mathbb{E}\left[\hat{f}(\mathbf{x}_0)\right]\right)^2 \\
&amp;- 2\left(f(\mathbf{x}_0) - \mathbb{E}\left[\hat{f}(\mathbf{x}_0)\right]\right)\left(\hat{f}(\mathbf{x}_0) - \mathbb{E}\left[\hat{f}(\mathbf{x}_0)\right]\right) \\
&amp;+ \left(\hat{f}(\mathbf{x}_0) - \mathbb{E}\left[\hat{f}(\mathbf{x}_0)\right]\right)^2\biggr]
\end{align}\]</span></p>
<p>Auch hier entfällt der mittlere Term, wenn wir den Erwartungswert in die Klammern reinnehmen, weil der zweite Teil <span class="math inline">\(\left(\mathbb{E}\left[\hat{f}(\mathbf{x}_0)\right] - \mathbb{E}\left[\hat{f}(\mathbf{x}_0)\right]\right)=0\)</span> ist. Was übrig bleibt ist folgendes:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}\left[(f(\mathbf{x}_0) - \hat{f}(\mathbf{x}_0))^2\right] &amp;= \mathbb{E}\left[\left(f(\mathbf{x}_0) - \mathbb{E}\left[\hat{f}(\mathbf{x}_0)\right]\right)^2\right] + \mathbb{E}\left[\left(\hat{f}(\mathbf{x}_0) - \mathbb{E}\left[\hat{f}(\mathbf{x}_0)\right]\right)^2\right] \\
&amp;= \left(f(\mathbf{x}_0) - \mathbb{E}\left[\hat{f}(\mathbf{x}_0)\right]\right)^2 + \mathbb{E}\left[\left(\hat{f}(\mathbf{x}_0) - \mathbb{E}\left[\hat{f}(\mathbf{x}_0)\right]\right)^2\right]
\end{align}\]</span></p>
<p>Schauen wir uns kurz die beiden Komponenten auf der rechten Seite etwas genauer an:</p>
<ul>
<li>
<span class="math inline">\(\left(f(\mathbf{x}_0) - \mathbb{E}\left[\hat{f}(\mathbf{x}_0)\right]\right)^2\)</span> ist der <strong>quadrierte Bias</strong> und misst die systematische Abweichung unseres geschätzten Modells <span class="math inline">\(\hat{f}\)</span> vom wahren unbekannten Modell <span class="math inline">\(f\)</span>. Je kleiner der Bias, desto tiefer der erwartete quadrierte Fehler. Wir können diesen Term der Einfachheit halber mit <span class="math inline">\(\left[\text{Bias}\left(\hat{f}(\mathbf{x}_0)\right)\right]^2\)</span> bezeichnen.</li>
<li>
<span class="math inline">\(\mathbb{E}\left[\left(\hat{f}(\mathbf{x}_0) - \mathbb{E}\left[\hat{f}(\mathbf{x}_0)\right]\right)^2\right]\)</span> ist nichts anderes als die Varianz unseres geschätzten Modells <span class="math inline">\(\hat{f}\)</span>. Sie misst, wie stark sich <span class="math inline">\(\hat{f}\)</span> im Schnitt verändert, wenn wir einen anderen Datensatz für das Training verwenden. Ein Modell mit hoher Varianz passt sich jeweils sehr stark an die Daten an. Je kleiner diese Varianz, desto tiefer der erwartete quadrierte Fehler. Wir bezeichnen diesen Term der Einfachheit halber als <span class="math inline">\(\text{Var}\left(\hat{f}(\mathbf{x}_0)\right)\)</span>.</li>
</ul>
<p>Nun sind wir endlich am Ziel angelangt und können den erwarteten quadrierten Fehler für die Beobachtung <span class="math inline">\((y_0,\mathbf{x}_0)\)</span> wie folgt aufschreiben:</p>
<p><span class="math display">\[
\mathbb{E}\left[\left(y_0 - \hat{f}(\mathbf{x}_0)\right)^2\right] = \text{Var}(\epsilon) + \left[\text{Bias}\left(\hat{f}(\mathbf{x}_0)\right)\right]^2 + \text{Var}\left(\hat{f}(\mathbf{x}_0)\right)
\]</span></p>
<p>Ein Modell mit <strong>viel Bias</strong> führt zu einer schlechten Vorhersagequalität (auf Trainings- und Testdaten), weil das Modell zu rigide ist, um den wahren Zusammenhang zwischen der Output-Variable und den Input-Variablen zu modellieren. Beispiel: wir verwenden ein einfaches lineares Regressionsmodell, um einen stark nicht-linearen Zusammenhang zwischen <span class="math inline">\(y_i\)</span> und <span class="math inline">\(\mathbf{x}_i\)</span> zu modellieren. Im Fall von Modellen mit viel Bias spricht man auch von <strong>Underfitting</strong>.</p>
<p>Ein Modell mit <strong>viel Varianz</strong> führt zu einer hervorragenden Vorhersagequalität auf den Trainingsdaten, aber zu einer sehr schlechten Vorhersagequalität auf den Testdaten. Das Problem hier ist, dass das Model zu flexibel ist gemessen an der Grösse des Trainingsdatensatzes. Das Modell passt sich so zu stark an die Trainingsdaten an und modelliert auch sogenanntes <strong>Noise</strong> (und nicht nur das <strong>Signal</strong> in den Daten). Beispiel: wir modellieren ein neuronales Netzwerk, haben aber nur einen Trainingsdatensatz von einigen hundert Beobachtungen. Im Fall von Modellen mit viel Varianz spricht man auch von <strong>Overfitting</strong>.</p>
<p>Warum spricht man von einem <strong>Tradeoff</strong>? Flexiblere Modelle haben oft einen kleinen Bias, aber hohe Varianz, während unflexible Modelle oft eine kleine Varianz, aber einen hohen Bias haben. Es existiert also ein Tradeoff zwischen Bias und Varianz und wir wollen beim Modellieren und vor allem beim Hyperparameter Tuning den optimalen Tradeoff finden.</p>
<p>In unserem Beispiel wenden wir ein regularisiertes Regressionsmodell an. Hier spielt der Hyperparameter <span class="math inline">\(\lambda\)</span> eine zentrale Rolle für den Tradeoff zwischen Bias und Variance. Ein zu tiefer Wert für <span class="math inline">\(\lambda\)</span> kann zu einem zu flexiblen Modell mit viel Varianz führen. Ein zu hoher Wert für <span class="math inline">\(\lambda\)</span> führt zu einem zu rigiden Modell mit viel Bias.</p>
</div>
<div id="polynomische-regression" class="section level2" number="4.7">
<h2>
<span class="header-section-number">4.7</span> Polynomische Regression<a class="anchor" aria-label="anchor" href="#polynomische-regression"><i class="fas fa-link"></i></a>
</h2>
<p>Wir machen hier nun einen kurzen Abstecher in die <strong>polynomische Regression</strong>, denn diese eignet sich sehr gut, um den Bias-Variance Tradeoff zu illustrieren.</p>
<p>Ein <strong>ganz wichtiger Punkt</strong>: das polynomische Regressionsmodell ist immer noch <strong>linear in den Parametern</strong>, es handelt sich also immer noch um ein lineares Modell. Sie sehen aber an obigen Modellkurven, dass dieses “lineare” Modell sehr wohl in der Lage ist, nicht-lineare Zusammenhänge zwischen <span class="math inline">\(x\)</span> und <span class="math inline">\(y\)</span> zu fitten!</p>
</div>
<div id="lineare-regression-in-r" class="section level2" number="4.8">
<h2>
<span class="header-section-number">4.8</span> Lineare Regression in R<a class="anchor" aria-label="anchor" href="#lineare-regression-in-r"><i class="fas fa-link"></i></a>
</h2>
<p>Base R vs. <code>tidymodels</code></p>
</div>
<div id="weiterführende-themen" class="section level2" number="4.9">
<h2>
<span class="header-section-number">4.9</span> Weiterführende Themen<a class="anchor" aria-label="anchor" href="#weiterf%C3%BChrende-themen"><i class="fas fa-link"></i></a>
</h2>
<p>Bayesianische Regression</p>
<p>Grob gesagt rechnen wir ein ML-Modell in zwei Schritten. In einem <strong>ersten Schritt</strong> entscheiden wir uns für die funktionale Form unseres Modells <span class="math inline">\(\hat{f}(\mathbf{x}_i)\)</span>. Man nennt dies in der Fachsprache <strong>Model Selection</strong>. Wir betrachten hier nur mal den vereinfachten Fall, in dem wir nur eine <span class="math inline">\(x_i\)</span>-Variable pro Beobachtung als Input haben. Folgende Funktionen bzw. Modelle sind mögliche Kandidaten:</p>
<ul>
<li>
<span class="math inline">\(f(x_i) = b_0 + b_1 \cdot x_i\)</span> (einfache lineare Regression)</li>
<li>
<span class="math inline">\(f(x_i) = b_0 + b_1 \cdot x_i + b_2 \cdot x_i^2\)</span> (polynomische Regression)</li>
<li><span class="math inline">\(f(x_i) = \begin{cases} \bar{y}_1, &amp; \text{falls}\; x_i &gt; x^*\\ \bar{y}_2, &amp; \text{sonst} \end{cases}\)</span></li>
</ul>
<p>Wir werden mit unserer Wahl der Funktion nie genau die wahre aber unbekannte Funktion <span class="math inline">\(f(\mathbf{x}_i)\)</span> treffen, aber wir versuchen möglichst nahe daran zu kommen.</p>
<div style="background-color:#DEEBF7; padding:10px">
<p><strong>“No Free Lunch” Theorem</strong></p>
<p>Das <em>No Free Lunch</em> Theorem besagt, dass es kein universal bestes Modell gibt. Das heisst, dass es je nach Problem und Datensatz andere Modelle bzw. Funktionen braucht, um gute Vorhersagen zu machen. Das ist der Hauptgrund, warum wir Ihnen möglichst viele verschiedene Tools mit auf den Weg geben wollen.</p>
</div>
<p><br></p>
<p>Im Vergleich zur Summe der quadrierten Residuen haben wir hier noch den Faktor <span class="math inline">\(\frac{1}{2n}\)</span> drin. Dieser Faktor macht daraus eine Art Mittelwert und darum wird diese Kostenfunktion typischerweise <strong>Mean Squared Error</strong> (MSE) genannt.</p>
<div style="background-color:#fef9e7; padding:10px">
<p><strong>Optional: Zerlegung des Vorhersagefehlers</strong></p>
<p>Wir wollen hier kurz anschauen, wie der <strong>Erwartungswert</strong> des quadrierten Fehlers, <span class="math inline">\(\left(y_i - \hat{f}(\mathbf{x}_i)\right)^2\)</span>, in zwei Komponenten zerlegt werden kann.</p>
<p>Dazu gilt folgendes:</p>
<ul>
<li>Von oben wissen wir, dass <span class="math inline">\(y_i = f(\mathbf{x}_i) + \epsilon\)</span> gilt.</li>
<li>Wir nehmen an, dass der Erwartungswert des unsystematischen Teils <span class="math inline">\(\epsilon\)</span> Null ist, also <span class="math inline">\(\text{E}(\epsilon)=0\)</span>.</li>
<li>Allgemeine Regel zur Varianz einer Zufallsvariable: <span class="math inline">\(\text{Var}(\epsilon) = \text{E}(\epsilon^2) - \text{E}(\epsilon)^2 = \text{E}(\epsilon^2) - 0^2 = \text{E}(\epsilon^2)\)</span>.</li>
<li>
<span class="math inline">\(\hat{f}\)</span> und <span class="math inline">\(\mathbf{x}_i\)</span> sind fix und gegeben (keine Zufallsvariablen) und darum gilt <span class="math inline">\(\text{E}\left(\hat{f}(\mathbf{x}_i)\right)=\hat{f}(\mathbf{x}_i)\)</span>.</li>
</ul>
<p>Nun können wir den <strong>Erwartungswert</strong> des quadrierten Fehlers rechnen:</p>
<p><span class="math display">\[\begin{align}
\text{E}\,\left[\left(y_i - \hat{f}(\mathbf{x}_i)\right)^2\right] &amp;= \text{E}\,\left[\left(f(\mathbf{x}_i) + \epsilon - \hat{f}(\mathbf{x}_i)\right)^2\right] \\
&amp;= \text{E}\,\left[f(\mathbf{x}_i)^2 - 2 \cdot f(\mathbf{x}_i) \cdot \hat{f}(\mathbf{x}_i) + \hat{f}(\mathbf{x}_i)^2 + 2 \cdot \epsilon \cdot f(\mathbf{x}_i) - 2 \cdot \epsilon \cdot \hat{f}(\mathbf{x}_i) + \epsilon^2 \right] \\
&amp;= f(\mathbf{x}_i)^2 - 2 \cdot f(\mathbf{x}_i) \cdot \hat{f}(\mathbf{x}_i) + \hat{f}(\mathbf{x}_i)^2 + 2 \cdot \text{E}(\epsilon) \cdot f(\mathbf{x}_i) - 2 \cdot \text{E}(\epsilon) \cdot \hat{f}(\mathbf{x}_i) + \text{E}(\epsilon^2) \\
&amp;= f(\mathbf{x}_i)^2 - 2 \cdot f(\mathbf{x}_i) \cdot \hat{f}(\mathbf{x}_i) + \hat{f}(\mathbf{x}_i)^2 + 2 \cdot 0 \cdot f(\mathbf{x}_i) - 2 \cdot 0 \cdot \hat{f}(\mathbf{x}_i) + \text{Var}(\epsilon) \\
&amp;= f(\mathbf{x}_i)^2 - 2 \cdot f(\mathbf{x}_i) \cdot \hat{f}(\mathbf{x}_i) + \hat{f}(\mathbf{x}_i)^2 + \text{Var}(\epsilon) \\
&amp;= \left(f(\mathbf{x}_i) - \hat{f}(\mathbf{x}_i)\right)^2 + \text{Var}(\epsilon)
\end{align}\]</span></p>
<p>Der erste Teil auf der rechten Seite der Formel beschreibt den <strong>reduzierbaren Fehler</strong> und der zweite Teil den <strong>nicht-reduzierbaren Fehler</strong>. Wir sehen also auch hier: es ist sehr wichtig, dass wir eine Funktion <span class="math inline">\(\hat{f}(\mathbf{x}_i)\)</span> schätzen, welche dem wahren funktionalen Zusammenhang <span class="math inline">\(f(\mathbf{x}_i)\)</span> möglichst nahe kommt.</p>
</div>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="intro-R.html"><span class="header-section-number">3</span> Einführung in das Programmieren mit R</a></div>
<div class="next"><a href="lin-class.html"><span class="header-section-number">5</span> Lineare Klassifikation</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#lin-reg"><span class="header-section-number">4</span> Lineare Regression</a></li>
<li><a class="nav-link" href="#ml-modelle-im-allgemeinen"><span class="header-section-number">4.1</span> ML-Modelle im Allgemeinen</a></li>
<li><a class="nav-link" href="#das-modell-ausgeschrieben"><span class="header-section-number">4.2</span> Das Modell (ausgeschrieben)</a></li>
<li><a class="nav-link" href="#das-modell-kompakt"><span class="header-section-number">4.3</span> Das Modell (kompakt)</a></li>
<li>
<a class="nav-link" href="#modelltraining"><span class="header-section-number">4.4</span> Modelltraining</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#perspektive-1-funktionsoptimierung"><span class="header-section-number">4.4.1</span> Perspektive 1: Funktionsoptimierung</a></li>
<li><a class="nav-link" href="#perspektive-2-wahrscheinlichkeitstheorie"><span class="header-section-number">4.4.2</span> Perspektive 2: Wahrscheinlichkeitstheorie</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#regularisierte-regression"><span class="header-section-number">4.5</span> Regularisierte Regression</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#ridge-regressionsmodell"><span class="header-section-number">4.5.1</span> Ridge Regressionsmodell</a></li>
<li><a class="nav-link" href="#lasso-regressionsmodell"><span class="header-section-number">4.5.2</span> LASSO Regressionsmodell</a></li>
</ul>
</li>
<li><a class="nav-link" href="#bias-variance-tradeoff"><span class="header-section-number">4.6</span> Bias-Variance Tradeoff</a></li>
<li><a class="nav-link" href="#polynomische-regression"><span class="header-section-number">4.7</span> Polynomische Regression</a></li>
<li><a class="nav-link" href="#lineare-regression-in-r"><span class="header-section-number">4.8</span> Lineare Regression in R</a></li>
<li><a class="nav-link" href="#weiterf%C3%BChrende-themen"><span class="header-section-number">4.9</span> Weiterführende Themen</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/martinSter/aml-book/blob/main/04-lin-reg.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/martinSter/aml-book/edit/main/04-lin-reg.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Machine Learning für das KMU</strong>" was written by Martin Sterchi. It was last built on 2024-04-01.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
