% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Machine Learning für das KMU},
  pdfauthor={Martin Sterchi},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Machine Learning für das KMU}
\author{Martin Sterchi}
\date{2023-11-24}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{uxfcber-das-buch}{%
\chapter*{Über das Buch}\label{uxfcber-das-buch}}
\addcontentsline{toc}{chapter}{Über das Buch}

Die Motivation für dieses Buch kam aus der Erkenntnis, dass viele kleine und mittelgrosse Unternehmen (KMU) in der Schweiz zwar über grosse Datenmengen verfügen, aber nicht das nötige Knowhow haben, um die Daten zu analysieren und für die Optimierung von Entscheidungsprozessen zu nutzen. Mit diesem Buch möchte ich einen kleinen Beitrag leisten, den Knowhow Transfer in die Unternehmen zu katalysieren. Das Buch versucht, sowohl die klassischen Machine Learning Methoden als auch neueste Entwicklungen im Deep Learning mit einem Fokus auf die Anwendung zu vermitteln. Deep Learning kann als eine Teilmenge des Machine Learning gesehen werden. Das heisst, jede Deep Learning Methode ist automatisch auch eine Machine Learning Methode. Machine Learning entält jedoch weitere Methoden, welche nicht dem Deep Learning zugeordnet werden können. Das Gebiet Machine Learning ist wiederum eine Teilmenge der Methoden der Künstlichen Intelligenz. Letztere enthält weitere Methoden, welche nicht dem Machine Learning zuzuordnen sind. Abbildung \ref{fig:kimldl} versucht diesen Sachverhalt schematisch darzustellen.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{images/KI_ML_DL} 

}

\caption{Unterscheidung zwischen KI, ML und DL. }\label{fig:kimldl}
\end{figure}

Wir werden im ganzen Buch die folgenden (üblichen) Abkürzungen verwenden:

\begin{itemize}
\tightlist
\item
  Künstliche Intelligenz = KI (oft spricht man auch von AI, was die Abkürzung für den englischen Begriff Artificial Intelligence ist).
\item
  Machine Learning = ML
\item
  Deep Learning = DL
\end{itemize}

Obwohl das Buch einen anwendungsorientierten Ansatz verfolgt, soll die mathematisch-statistische Intuition hinter den beschriebenen Modellen und Methoden nicht zu kurz kommen. Diese Intuition ist aus meiner Sicht zwingend, um beurteilen zu können, ob sich ein Modell überhaupt für ein gegebenes Problem eignet. Am Schluss geht es nämlich darum, dass wir mit dem Einsatz von Machine Learning einen Mehrwert für ein Unternehmen oder für die Gesellschaft schaffen können. Das erfordert, dass wir uns eingehend und kritisch mit unseren Modellen und Resultaten auseinander setzen.

\hypertarget{zielgruppe}{%
\section*{Zielgruppe}\label{zielgruppe}}
\addcontentsline{toc}{section}{Zielgruppe}

Das Buch richtet sich insbesondere an Fachhochschulstudierende in der Schweiz mit einem intrinsischen Interesse an quantitativen Methoden und Machine Learning. Vorausgesetzt werden Mathematikkenntnisse auf Stufe Mittelschule (Berufs- oder gymnasiale Matur), d.h. Sie sollten vertraut sein mit den Grundlagen bezüglich mathematischer Funktionen, der Integral- und Differentialrechnung sowie den wichtigsten Resultaten aus der Algebra. Ausserdem gehe ich davon aus, dass Sie bereits eine Einführung in das Thema Statistik besucht haben und Konzepte aus der deskriptiven Statistik (Mittelwert, Median, Varianz, Quantile, etc.) sowie aus der Inferenzstatistik (Verteilungen, statistisches Testen, etc.) bekannt sind.

Bevor Sie sich aber nun Sorgen machen: Kapitel \ref{basics} enthält eine Einführung in die wichtigsten Mathematik- und Statistikgrundlagen, die nötig sind für das Verständnis von Machine Learning Modellen.

Da ich mit diesem Buch einen anwendungsorientierten Ansatz verfolge, werden wir auch in das Programmieren einsteigen. Dazu verwenden wir in diesem Buch die Programmiersprache \texttt{R}. Es werden keine Vorkenntnisse vorausgesetzt. Kapitel \ref{intro-R} enthält eine kurze Einführung in die Programmiersprache \texttt{R} und verweist Sie auf weiterführende Ressourcen zum Thema Programmieren. Jedes Modell, das wir uns anschauen werden, ist mit R-Code dokumentiert, so dass Sie lernen, wie die Modelle in der Praxis angewendet werden können.

\hypertarget{struktur-des-buchs}{%
\section*{Struktur des Buchs}\label{struktur-des-buchs}}
\addcontentsline{toc}{section}{Struktur des Buchs}

Das Buch enthält folgende Kapitel:

\begin{itemize}
\tightlist
\item
  Kapitel \ref{intro}: Einführung in das Thema Machine Learning mit Definitionen sowie Anwendungsbeispielen.
\item
  Kapitel \ref{basics}: Wichtigste Mathematik- und Statistikgrundlagen, die für das Verständnis der Modelle in den späteren Kapitel elementar sind.
\item
  Kapitel \ref{intro-R}: Einführung in das Programmieren mit \texttt{R} sowie Überblick über die wichtigsten \texttt{R}-Packages, die wir verwenden werden.
\item
  \ldots{}
\end{itemize}

\hypertarget{lizenz}{%
\section*{Lizenz}\label{lizenz}}
\addcontentsline{toc}{section}{Lizenz}

Das vorliegende Buch ist unter Lizenz \href{https://creativecommons.org/licenses/by-nc-sa/4.0/deed.de}{CC BY-NC-SA 4.0 DEED} (Namensnennung, nicht-kommerziell, Weitergabe unter gleichen Bedingungen 4.0 International) lizenziert. Bitte halten Sie sich an die Lizenzbedingungen.

\hypertarget{weiterfuxfchrende-literatur}{%
\section*{Weiterführende Literatur}\label{weiterfuxfchrende-literatur}}
\addcontentsline{toc}{section}{Weiterführende Literatur}

Ein grosser Teil des vorliegenden Buchs baut auf bestehenden Büchern zum Thema Machine Learning auf. Ich werde im Buch immer wieder auf die Quellen verweisen. Die wichtigsten Referenzen für dieses Buch sind folgende:

\begin{itemize}
\tightlist
\item
  Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani. (2021). \href{https://www.statlearning.com/}{An Introduction to Statistical Learning: with Applications in R.} New York: Springer. 2nd Edition.
\item
  Aurélien Géron. (2019). \href{https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/}{Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems.} Sebastopol: O'Reilly Media Inc.~3rd Edition.
\item
  Christopher M. Bishop. (2006). \href{https://link.springer.com/book/9780387310732}{Pattern Recognition and Machine Learning.} Berlin, Heidelberg: Springer.
\item
  Kevin P. Murphy. (2012). \href{https://mitpress.mit.edu/9780262018029/machine-learning/}{Machine Learning A Probabilistic Perspective.} The MIT Press.
\end{itemize}

Die ersten beiden Referenzen sind einführende Texte und können problemlos parallel zum vorliegenden Buch gelesen werden. Die letzten zwei Referenzen sind fortgeschrittene Texte und ich empfehle, sie erst nach dem vollständigen Verständnis des vorliegenden Buchs oder der ersten beiden Referenzen zu lesen.

\hypertarget{kontakt}{%
\section*{Kontakt}\label{kontakt}}
\addcontentsline{toc}{section}{Kontakt}

Für Fragen und Anregungen zum Buch stehe ich gerne zur Verfügung:

Martin Sterchi\\
Riggenbachstrasse 16\\
4600 Olten\\
\href{mailto:martin.sterchi@fhnw.ch}{\nolinkurl{martin.sterchi@fhnw.ch}}

\hypertarget{intro}{%
\chapter{Einführung}\label{intro}}

In diesem Kapitel geht es darum zu verstehen, was ML überhaupt ist, warum es nützlich sein kann und was typische Anwendungsfälle von ML sind. Wir werden ausserdem die verschiedenen Arten von ML kennen lernen.

\hypertarget{was-ist-machine-learning}{%
\section{Was ist Machine Learning?}\label{was-ist-machine-learning}}

Kurze Geschichte von ML

Wie der Name sagt, geht es im ML darum, dass eine Maschine (oder präziser, ein Computer) aus einem gegebenen Datensatz automatisch lernt, ohne dass ein Mensch dem Computer sagen muss, was er lernen soll. Der Mensch gibt jedoch dem Computer die Rahmenbedingungen für das selbständige Lernen vor.

Bevor wir etwas konkreter anschauen, wie genau ein Computer selbständig aus Daten lernen kann, schauen wir uns die Definitionen von zwei Experten im Gebiet ML an:

\emph{``{[}Machine Learning is the{]} field of study that gives computers the ability to learn without being explicitly programmed.''} Arthur Samuel, 1959

\emph{``Machine Learning is the science (and art) of programming computers so they can learn from data.''} Aurélien Géron\footnote{Aurélien Géron. (2019). Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. Sebastopol: O'Reilly Media Inc.~3rd Edition.}

Zusammenfassend lässt sich sagen, dass wir mit ML dem Computer die Möglichkeit geben, automatisch und selbständig aus Daten zu lernen. Nichtsdestotrotz braucht es Sie als ML-Expert*in, und zwar wie folgt:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sie entscheiden sich für ein spezifisches ML Modell. Typischerweise kann ein ML Modell durch eine mathematische Funktion (Kapitel \ref{basics}) charakterisiert werden. ML Modelle können unterschiedlich flexibel sein und es liegt im Ermessen von Ihnen, wie flexibel das Modell sein soll. Grundsätzliche gilt bei der Wahl des Modells, dass flexiblere Modelle komplexere Sachverhalte abbilden können. Ein zu flexibles Modell kann aber zu Overfitting führen, aber dazu später mehr.
\item
  Sobald Sie das Modell ausgewählt haben, übergeben Sie dem Computer das Modell, einen Datensatz sowie einen Lernalgorithmus. Nun hat der Computer alle Zutaten, um automatisch zu lernen, doch was lernt er eigentlich? Der Computer lernt die Parameter Ihres gewählten Modells, so dass das Modell sich optimal an die Daten anpasst.
\item
  Das so erlernte Modell kann nun entweder verwendet werden, um \ldots{}
\end{enumerate}

\hypertarget{wann-macht-es-sinn-ml-einzusetzen}{%
\section{Wann macht es Sinn ML einzusetzen?}\label{wann-macht-es-sinn-ml-einzusetzen}}

Ein ML Modell zu trainieren kann viel Zeit und Geld kosten. Zum Beispiel müssen Sie unter Umständen überhaupt erst die Daten sammeln, um ein Modell zu erlernen. Oder das Projekt ist so komplex, dass Sie als Analyst*in unzählige Stunden benötigen, um die Daten überhaupt erst in eine Form zu bringen, die es erlaubt ein Modell zu trainieren. Für neuartige DL Modelle oder Generative KI kann das Trainieren bzw. Lernen eines Modells durch den reinen Stromverbrauch bzw. die vom Cloud-Betreibeber in Rechnung gestellten Kosten so hoch sein, dass sich Ihr ursprüngliches Vorhaben nicht mehr lohnt. Es ist also ungemein wichtig, dass Sie sich vor Projektbeginn gut überlegen, ob ML für Ihr vorliegendes Problem überhaupt Sinn macht und einen Mehrwert generieren kann.

Folgende Daumenregeln können Ihnen dabei helfen, zu entscheiden, ob ML für Ihr Projekt Sinn macht:

\begin{itemize}
\tightlist
\item
  Der manuelle Arbeitsaufwand ist sehr gross, wenn das Problem durch Menschen gelöst werden soll. Das Problem ist aber ansonsten klar strukturiert und benötigt keinen grossen kognitiven Einsatz eines Menschen. Beispiel: In den Post-Verteilzentren werden die von Hand geschriebenen PLZ problemlos mittels Computer bzw. ML Modellen ``gelesen'' und die Briefe und Pakete entsprechend sortiert.
\item
  Komplexe Probleme, in denen ein Mensch keinen Überblick hat, weil so viele Daten vorhanden sind (Bsp. Anscome Quartett).
\item
  Wenn sich das Problem dynamisch verändert. ML erlaubt es uns, ein Modell effizient mit neuen Daten zu rechnen und so an das veränderte Problem anzupassen.
\item
  \ldots{}
\end{itemize}

\hypertarget{anwendungsfuxe4lle-von-ml}{%
\section{Anwendungsfälle von ML}\label{anwendungsfuxe4lle-von-ml}}

Stellen Sie sich vor, wir haben einen Datensatz mit 300 Spam Emails und 700 ``Ham'' Emails (kein Spam). Ohne Machine Learning müssten wir nun von Hand die 300 Spam Emails mit den 700 Ham Emails vergleichen und versuchen, Muster zu finden, die es uns erlauben Regeln aufzustellen, um die Spam Emails korrekt zu klassifizieren (z.B. Spam enthält tendenziell eher Geldbeträge oder Preise als Ham). Danach könnten wir die Regeln mit R implementieren. Dann stellt sich aber auch noch die Frage, wie die verschiedenen Regeln miteinander kombiniert werden, um eine Klassifikation zu machen. Dieses Vorgehen würde sehr viel zu tun geben und es würde gezwungenermassen zu willkürlichen Entscheidungen führen.

Machine Learning führt zu i) weniger Aufwand und ii) besseren Lösungen, indem wir in einem R-Skript ein Modell (z.B. logistische Regression) aufsetzen und dann dem Modell die Daten in geeigneter Form füttern. Danach lernt der Computer selbständig, wie er die Emails bestmöglich in Spam und Ham klassifiziert.

ML Beispiele
- Spam Filter
- ChatGPT
- Face Recognition in Fotos

\hypertarget{supervised-vs.-unsupervised-learning}{%
\section{Supervised vs.~Unsupervised Learning}\label{supervised-vs.-unsupervised-learning}}

Beim Supervised Learning geht es um ML Probleme, in denen sowohl Input-Daten als auch ein Output vorhanden ist. Für die Input-Daten gibt es ganz viele verschiedene Begriffe, die synonym verwendet werden: z.B. Features, unabhängige Variablen, Attribute, Prädiktoren. Dasselbe gilt für den Output, hier gibt es folgende Synonyme: Zielvariable, abhängige Variable, Label, oder auch einfach y.

Ziel ist es, ein Modell zu lernen, das basierend auf den Input-Daten möglichst gute Vorhersagen für den Output macht. Es geht also hier um Vorhersageprobleme. In einem gewissen Sinn ist der Output der Supervisor, der den Lernprozess des Modells überwacht.

Neben dem Supervised und dem Unsupervised Learning gibt es noch eine dritte erwähnenswerte ML Kategorie, nämlich Reinforcement Learning (RL). Dieser Kategorie gehören Modelle an, die sogenannte (virtuelle) Agenten so trainieren, dass sie langfristig möglichst optimal handeln. Das bekannteste Beispiel aus dem RL ist Googles AlphaGo Agent, welcher den menschlichen Go Weltmeister im Jahr 2017 schlug.

\hypertarget{regression-vs.-klassifikation}{%
\section{Regression vs.~Klassifikation}\label{regression-vs.-klassifikation}}

Im Bereich des Supervised Learnings unterscheiden wir zwischen Regressions- und Klassifikationsproblemen.

Im Regressionsproblem ist der Output bzw. die Zielvariable eine stetige Variable (Intervall- oder Verhältnisskalierung), d.h. die Variable enthält numerische Werte.

Im Klassifikationsproblem ist der Output bzw. die Zielvariable eine kategorische Variable (Nominal- oder Ordinalskalierung).

\hypertarget{parametrische-vs.-nicht-parametrische-modelle}{%
\section{Parametrische vs.~nicht-parametrische Modelle}\label{parametrische-vs.-nicht-parametrische-modelle}}

K-Nearest Neighbor als erstes (nicht-parametrisches) Beispiel
Hier erste kleine App

\hypertarget{machine-learning-pipeline}{%
\section{Machine Learning Pipeline}\label{machine-learning-pipeline}}

Pipeline zeigen

\hypertarget{basics}{%
\chapter{Mathematik- und Statistik-Grundlagen}\label{basics}}

In diesem Kapitel repetieren wir die wichtigsten Grundlagen aus der Mathematik und Statistik, die es braucht, um Machine Learning Modelle zu verstehen. Das Thema \emph{Lineare Algebra} wird für die meisten von Ihnen wahrscheinlich Neuland sein.

\hypertarget{funktionen}{%
\section{Funktionen}\label{funktionen}}

Eine Funktion, die wir in der Mathematik typischerweise mit \(f\) bezeichnen, ordnet jedem \textbf{Argument} \(x\) aus dem Definitionsbereich \(D\) (engl. \emph{Domain}) \textbf{genau einen Wert \(y\)} aus dem Wertebereich \(W\) (engl. \emph{Codomain}) zu. Oft sind \(D\) und \(W\) die Menge der reellen Zahlen, also \(\mathbb{R}\). Die Menge der reellen Zahlen enthält alle möglichen Zahlen, die Sie sich vorstellen können.\footnote{Einzige Ausnahme sind die komplexen Zahlen.} Zum Beispiel die Zahlen \(3\), \(-4.247\), \(\sqrt{14}\), \(5/8\), etc.

Wie eine Funktion grafisch aussieht, ist aus Panel (a) der Abbildung \ref{fig:functions} ersichtlich. Hier zeigen wir die Form einer Funktion in einem kartesischen Koordinatensystem. Die Funktionskurve weist jedem Wert \(x\) auf der x-Achse genau einen Wert \(y\) auf der y-Achse zu. Der wichtigste Teil der oben aufgeführten Definition ist der Teil ``genau einen Wert'', denn eine Funktion kann einem Element \(x\) nicht zwei oder mehr Werte zuweisen, sondern nur genau einen. Genau aus diesem Grund handelt es sich bei Panel (b) in Abbildung \ref{fig:functions} \emph{nicht} um eine Funktion, da gewissen \(x\)-Werten mehrere Werte \(y\) zugeordnet werden. \emph{Wichtig}: das heisst aber nicht, dass zwei verschiedenen \(x\)-Werten, nennen wir sie \(x'\) und \(x''\), derselbe \(y\)-Wert zugeordnet werden kann (vgl. Panel (a)).

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{images/Functions} 

}

\caption{(a) Eine Funktion, die jedem x-Wert genau einen y-Wert zuweist. (b) Keine Funktion. }\label{fig:functions}
\end{figure}

Mathematisch wird diese allgemeine Definition einer Funktion häufig wie folgt beschrieben:

\[
f : x \mapsto y
\]
Wir haben also eine Funktion \(f\), die jedem Element \(x\) genau einen Wert \(y\) zuweist. Der Pfeil in obiger mathematischer Schreibweise beschreibt genau dieses Mapping. Wie genau dieses Mapping einem Argument \(x\) den entsprechenden \(y\)-Wert zuordnet, wird durch die Funktion \(f(x)\) beschrieben. In den folgenden Abschnitten schauen wir uns typische Beispiele von Funktionen an, angefangen mit linearen Funktionen. Doch vorher wollen wir uns kurz überlegen, warum Funktionen für das Machine Learning überhaupt wichtig sind. Ein grosser Teil des Machine Learnings, der \textbf{Supervised Learning} genannt wird, befasst sich mit dem Problem, wie eine Zielvariable \(y\) mithilfe von einem oder mehreren Prädiktoren \(x\) vorhergesagt werden kann. Ein Machine Learning Modell ist darum nichts anderes als eine Funktion \(y=f(x)\), die basierend auf den Prädiktoren \(x\) die Zielvariable \(y\) möglichst gut beschreiben kann.\footnote{Zumindest aus einer nicht-probabilistischen Perspektive.}

\hypertarget{lineare-funktionen}{%
\subsection{Lineare Funktionen}\label{lineare-funktionen}}

Nun schauen wir uns an, wie eine \textbf{lineare} Funktion aussieht. Eine lineare Funktion kann allgemein wie folgt geschrieben werden:

\[
y = f(x) = a \cdot x + b
\]
Obige Funktionsgleichung besagt, dass wir den entsprechenden \(y\)-Wert kriegen, indem wir den Wert des Arguments \(x\) mit \(a\) multiplizieren und danach eine Konstante \(b\) addieren. \(a\) und \(b\) sind die \textbf{Parameter} dieser Funktion. Die konkreten Zahlenwerte dieser beiden Parameter definieren, wie die Funktion am Schluss genau aussieht.

Eine lineare Funktion hat auch eine geometrische Interpretation und zwar entspricht eine lineare Funktion einer Gerade. Das ist auch der Grund, warum wir diese Funktionen \textbf{linear} nennen, sie können graphisch durch eine ``Linie'' dargestellt werden. Der Parameter \(a\) ist die Steigung dieser Geraden und der Parameter \(b\) entspricht dem Ort, wo die Gerade die y-Achse schneidet (sogenannter y-Achsenabschnitt).

Am besten schauen wir uns ein paar konkrete Beispiele an (Abb. \ref{fig:lin-func}).

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{02-basics_files/figure-latex/lin-func-1} \includegraphics[width=0.5\linewidth]{02-basics_files/figure-latex/lin-func-2} 

}

\caption{Beispiele linearer Funktionen.}\label{fig:lin-func}
\end{figure}

Aus der linken Abbildung können wir ablesen, dass die Steigung dieser Geraden \(\frac{\Delta y}{\Delta x}=\frac{2}{2}=1\) ist und dass die Gerade die y-Achse am Ort \(1\) schneidet. Die entsprechende lineare Funktion kann dementsprechend als \(y = x + 1\) geschrieben werden.\footnote{Wir müssen hier die Steigung \(1\) nicht explizit schreiben, aber selbstverständlich ist es nicht falsch die lineare Funktion als \(y = 1\cdot x + 1\) zu schreiben.}

Aus der rechten Abbildung können wir ablesen, dass die Steigung \(\frac{\Delta y}{\Delta x}=\frac{-1}{2}=-0.5\) ist und dass die Gerade die y-Achse am Ort \(-2\) schneidet. Die entsprechende lineare Funktion kann dementsprechend als \(y = -0.5\cdot x -2\) geschrieben werden.

Es ist wichtig zu sehen, dass der Effekt einer Veränderung von \(x\) (also \(\Delta x\)) auf \(y\) überall derselbe ist. Es spielt also keine Rolle, ob wir von \(x=-2\) zu \(x=-1\) gehen oder von \(x=100\) zu \(x=101\), die entsprechende Veränderung in \(y\) (also \(\Delta y\)) wird dieselbe sein. Das muss so sein, denn die Gerade steigt (oder sinkt) mit konstanter Steigung.

\textbf{Aufgaben}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Zeichnen Sie die Funktion \(y = 2\cdot x\) in ein Koordinatensystem ein. Warum fehlt der Parameter \(b\)?
\item
  Zeichnen Sie die Funktion \(y=-3\) in ein Koordinatensystem ein. Ist das überhaupt eine Funktion nach obiger Definition?
\end{enumerate}

\hypertarget{quadratische-funktionen}{%
\subsection{Quadratische Funktionen}\label{quadratische-funktionen}}

Nun wollen wir uns eine etwas interessantere (und flexiblere) Familie von Funktionen anschauen, nämlich \textbf{quadratische} Funktionen. Auch hier wollen wir die Funktion erstmal allgemein aufschreiben:

\[
y = f(x) = a \cdot x^2 + b \cdot x + c
\]
Eine quadratische Funktion hat drei \textbf{Parameter}, nämlich \(a\), \(b\) und \(c\). Grafisch entspricht die quadratische Funktion einer \textbf{Parabel} (vgl. Abb. \ref{fig:quad-func}). Die Parameter sind hier nicht mehr so einfach grafisch zu interpretieren, aber die vier Beispiele in unten stehender Abbildung geben Anhaltspunkte, was passiert, wenn die Parameterwerte sich ändern.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{02-basics_files/figure-latex/quad-func-1} 

}

\caption{Beispiele quadratischer Funktionen.}\label{fig:quad-func}
\end{figure}

\textbf{Aufgaben}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sie haben folgende quadratische Gleichung: \(y = 2 \cdot x^2 + x - 2\). Berechnen Sie mit der bekannten Lösungsformel \(x_{1,2}=\frac{-b \pm \sqrt{b^2 - 4ac}}{2a}\) die Orte auf der x-Achse, wo die Parabel die Achse schneidet (oder einfacher gesagt die Nullstellen).
\item
  Verwenden Sie folgenden R-Code, um beliebige quadratische Funktionen grafisch darzustellen, indem Sie die Parameterwerte auf der ersten Code-Zeile verändern.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Parameter setzen}
\NormalTok{a }\OtherTok{\textless{}{-}} \DecValTok{2}\NormalTok{; b }\OtherTok{\textless{}{-}} \DecValTok{0}\NormalTok{; c }\OtherTok{\textless{}{-}} \DecValTok{1}
\CommentTok{\# Quadratische Funktion}
\NormalTok{quad }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x, a, b, c) \{a }\SpecialCharTok{*}\NormalTok{ x}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ x }\SpecialCharTok{+}\NormalTok{ c\}}
\CommentTok{\# x{-}Werte}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{, }\FloatTok{0.01}\NormalTok{)}
\CommentTok{\# y{-}Werte}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{quad}\NormalTok{(x, a, b, c)}
\CommentTok{\# Plot}
\FunctionTok{plot}\NormalTok{(x, y, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{col =} \StringTok{"darkcyan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Sie wundern sich nun vielleicht, könnte man nicht auch eine Funktion antreffen, in der \(x^3\), \(x^4\), etc. vorkommen? Das ist selbstverständlich möglich. In diesem Fall spricht man dann von einem sogenannten \textbf{Polynom}. Die höchste Potenz des Arguments \(x\) definiert den Grad des Polynoms.

Schauen wir uns doch am besten gleich wieder ein Beispiel an:

\[
y = f(x) = 1 \cdot x^4 - 2 \cdot x^3 - 5 \cdot x^2 + 8 \cdot x - 2
\]
Die Visualisierung dieser Funktion ist in Abb. \ref{fig:poly-func} gegeben. Diese Funktion ist nun bereits enorm flexibel und kann je nach Parameterwerten ganz unterschiedliche Zusammenhänge abbilden.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{02-basics_files/figure-latex/poly-func-1} 

}

\caption{Beispiel einer polynomischen Funktion vierten Grades.}\label{fig:poly-func}
\end{figure}

\textbf{Aufgaben}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Eine quadratische Funktion ist ein Polynom welchen Grades?
\item
  Handelt es sich bei der Funktion \(y=2x^5 + x + 1\) immer noch um ein Polynom? Falls ja, ein Polynom welchen Grades?
\item
  Handelt es sich bei der Funktion \(y = x^{0.5} + 2\) um ein Polynom?
\end{enumerate}

\hypertarget{funktionen-mehrerer-argumente}{%
\subsection{Funktionen mehrerer Argumente}\label{funktionen-mehrerer-argumente}}

Bisher haben wir nur Funktionen mit \textbf{einem Argument} \(x\) angeschaut, doch die meisten für das Machine Learning interessanten Funktionen sind Funktionen \textbf{mehrerer Argumente}.

Der Einfachheit halber schauen wir uns hier nur mal eine \textbf{lineare} Funktion zweier Argumente, nennen wir sie \(x_1\) und \(x_2\), an, denn diese können wir in 3D immer noch visualisieren. Wir betrachten folgende Funktion: \(y = f(x_1,x_2) = 1 \cdot x_1 + 0.5 \cdot x_2 + 5\).

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{02-basics_files/figure-latex/plane-1} 

}

\caption{Lineare Funktion zweier Argumente (Ebene).}\label{fig:plane}
\end{figure}

Aha! Während eine lineare Funktion eines Arguments grafisch einer Gerade entspricht, sehen wir nun, dass eine lineare Funktion zweier Argumente nichts anderes als eine Ebene darstellt. Wir sehen, dass die Ebene die y-Achse am Punkt \(5\) schneidet. Etwas schwieriger zu sehen ist die Steigung der Ebene in die Richtung der \(x_1\)-Achse und in die Richtung der \(x_2\)-Achse. Sie können aber vielleicht bereits erraten, dass die (partiellen) Steigungen \(1\) und \(0.5\) betragen.

Die Funktion ordnet jeden möglichen Punkt \((x_1,x_2)\) einem Punkt auf der Ebene zu. Wir können zum Beispiel für den in Abb. \ref{fig:plane} eingezeichneten Punkt \((6,4)\) den entsprechenden Punkt auf der Ebene ausrechnen:

\[ \begin{split}
y &= 1 \cdot x_1 + 0.5 \cdot x_2 + 5\\
&= 1 \cdot 6 + 0.5 \cdot 4 + 5\\
&= 13
\end{split}\]

Selbstverständlich könnten wir uns nun auch quadratische Funktionen oder Polynome mehrerer Argumente anschauen, aber darauf verzichten wir vorerst.

\hypertarget{potenzen-und-logarithmen}{%
\subsection{Potenzen und Logarithmen}\label{potenzen-und-logarithmen}}

Blabla\ldots{}

\hypertarget{integral--und-differentialrechnung}{%
\section{Integral- und Differentialrechnung}\label{integral--und-differentialrechnung}}

Olteanu materials:
Local vs.~global minima
From a maximization to a minimization problem
Basic definition of derivative
Differentiation rules
local min., max. and saddle point
Second derivative test
Partial derivatives
What is a gradient? What is Hessian? What is Jacobian?
Chain rules
Lagrange optimization

\hypertarget{lineare-algebra}{%
\section{Lineare Algebra}\label{lineare-algebra}}

Olteanu materials:
What is a scalar? What is a vector? What is a matrix?
Vector norms
Inner products
Symmetric, diagonal, square and identity matrix
Associative, commutative laws for matrices
Matrix addition and multiplication
Matrix inversion
Eigenvectors and eigenvalues
Quadratic form and positive (semi-) definiteness
Differentiation rules for matrices

\hypertarget{wahrscheinlichkeitsrechnung}{%
\section{Wahrscheinlichkeitsrechnung}\label{wahrscheinlichkeitsrechnung}}

Olteanu materials:
Sample space and axioms of probability
Conditional probability definition
Discrete vs.~continuous random variables
Joint probability distributions
Expectation and variance, covariance (always for discrete and continuous)
Bernoulli, Binomial, Normal, Multivariate Normal, Laplace

\hypertarget{diskrete-zufallsvariablen}{%
\subsection{Diskrete Zufallsvariablen}\label{diskrete-zufallsvariablen}}

Wir werden später sehen, dass im Machine Learning oftmals Dinge als \textbf{Zufallsvariablen} modelliert werden. Eine Zufallsvariable \(X\) ist eine Variable, für die der konkrete Wert nicht von vornherein klar ist. Wir können mit \(X\) zum Beispiel das Resultat eines Münzwurfs modellieren. Die zwei möglichen Resultate sind Kopf und Zahl. Vor dem Münzwurf ist nicht klar, ob Kopf oder Zahl erscheinen wird. Genau darum modellieren wir das Resultat des Münzwurfs als Zufallsvariable.

Es gibt in diesem einfachen Beispiel nur zwei mögliche Resultate (Kopf und Zahl), d.h. die Anzahl möglicher Resultate ist endlich (= nicht unendlich). Darum handelt es sich in diesem Fall um eine \textbf{diskrete} Zufallsvariable.

\hypertarget{verteilungen}{%
\section{Verteilungen}\label{verteilungen}}

\hypertarget{intro-R}{%
\chapter{Einführung in das Programmieren mit R}\label{intro-R}}

leaRn Materialen

tidymodels

Referenzen auf andere Ressourcen (Hadley et al.)

\hypertarget{lin-reg}{%
\chapter{Lineare Regression}\label{lin-reg}}

\hypertarget{lin-class}{%
\chapter{Lineare Klassifikation}\label{lin-class}}

\hypertarget{ml-pipeline}{%
\chapter{Machine Learning Pipeline}\label{ml-pipeline}}

\hypertarget{trees}{%
\chapter{Decision Trees}\label{trees}}

\hypertarget{ensembles}{%
\chapter{Ensembles}\label{ensembles}}

\hypertarget{svm}{%
\chapter{Support Vector Machines}\label{svm}}

\hypertarget{ann}{%
\chapter{Artificial Neural Networks}\label{ann}}

\hypertarget{cnn}{%
\chapter{Convolutional Neural Networks}\label{cnn}}

\hypertarget{rnn}{%
\chapter{Recurrent Neural Networks}\label{rnn}}

\hypertarget{gen-AI}{%
\chapter{Generative AI}\label{gen-AI}}

  \bibliography{book.bib,packages.bib}

\end{document}
